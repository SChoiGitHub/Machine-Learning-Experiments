{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FlowerClassifier",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WEos5ZcT9JI",
        "colab_type": "text"
      },
      "source": [
        "Flower Classification Experiment\n",
        "\n",
        "The dataset is curated by the Tensorflow Team and contains 5 classes of flowers: Roses, Tulips, Dandelions, Sunflowers, and Daisies.\n",
        "\n",
        "This experiment wants to explore the usage of CNNs and Keras Tuner, specifically Hyperband."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DQSe9CtNfTg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "6480e5c6-c61b-41b7-a327-043f2022eabd"
      },
      "source": [
        "'''\n",
        "Description: https://www.tensorflow.org/datasets/catalog/tf_flowers\n",
        "Download: http://download.tensorflow.org/example_images/flower_photos.tgz\n",
        "'''\n",
        "\n",
        "#Either uncomment the below line and execute it OR download it yourself.\n",
        "#!wget http://download.tensorflow.org/example_images/flower_photos.tgz && tar -zxf flower_photos.tgz"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-08 16:19:55--  http://download.tensorflow.org/example_images/flower_photos.tgz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 142.250.13.128, 2a00:1450:400c:c03::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|142.250.13.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228813984 (218M) [application/x-compressed-tar]\n",
            "Saving to: ‘flower_photos.tgz’\n",
            "\n",
            "flower_photos.tgz   100%[===================>] 218.21M  78.5MB/s    in 2.8s    \n",
            "\n",
            "2020-07-08 16:19:58 (78.5 MB/s) - ‘flower_photos.tgz’ saved [228813984/228813984]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "63N-qizug8te",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "outputId": "1d64fe0f-5a7f-4e08-b6c6-eee0fb6a0214"
      },
      "source": [
        "#Get Keras Tuner\n",
        "!pip3 install keras-tuner"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/f7/4b41b6832abf4c9bef71a664dc563adb25afc5812831667c6db572b1a261/keras-tuner-1.0.1.tar.gz (54kB)\n",
            "\r\u001b[K     |██████                          | 10kB 23.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 20kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 30kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 40kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 51kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.18.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.8.7)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.22.2.post1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->keras-tuner) (0.15.1)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.1-cp36-none-any.whl size=73200 sha256=2a1a3679c7c4b508b23f949fafd6cbd5b0c85937857c75b7d63c77b87d626864\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/cc/62/52716b70dd90f3db12519233c3a93a5360bc672da1a10ded43\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp36-none-any.whl size=15356 sha256=d9e8ab3266c1a03a68f7a178989fa263776a87ac2cdca2bc7ede6bbc2b1d526a\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner\n",
            "Successfully installed colorama-0.4.3 keras-tuner-1.0.1 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZrErtDuNLUZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "76232a04-1c3c-4f5a-f122-43457825c1f8"
      },
      "source": [
        "'''\n",
        "Hyperband usage.\n",
        "Goal: Use Hyperband to see which models can best perform flower\n",
        "      classification.\n",
        "'''\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import kerastuner as kt\n",
        "import os\n",
        "\n",
        "#Obtain Data\n",
        "dataGen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    rotation_range=45,\n",
        "    width_shift_range=0.15,\n",
        "    height_shift_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.5,\n",
        "    validation_split=0.2)\n",
        "\n",
        "IMG_SIZE=128\n",
        "\n",
        "train = dataGen.flow_from_directory(\n",
        "    './flower_photos',\n",
        "    target_size=(IMG_SIZE,IMG_SIZE),\n",
        "    subset='training')\n",
        "val = dataGen.flow_from_directory(\n",
        "    './flower_photos',\n",
        "    target_size=(IMG_SIZE,IMG_SIZE),\n",
        "    subset='validation')\n",
        "\n",
        "def build_model(hp):\n",
        "  dropout = 0.5\n",
        "  convParams = [\n",
        "                (\n",
        "                hp.Int('convFiltersSize'+str(i),32,64),\n",
        "                3\n",
        "                )\n",
        "                for i in range(0,hp.Int('convLayerCount',1,3))\n",
        "              ]\n",
        "  maxPoolParams = 2\n",
        "  convFunc = 'relu'\n",
        "\n",
        "  annParams = [\n",
        "                hp.Int('annLayerSize'+str(i),32,64)\n",
        "                for i in range(0,hp.Int('annLayerCount',1,3))\n",
        "              ]\n",
        "\n",
        "  annFunc = 'relu'\n",
        "\n",
        "  cnnLayers = []\n",
        "  for (filter,kernel) in convParams:\n",
        "    cnnLayers += [layers.Conv2D(filter,(kernel,kernel),activation=convFunc)]\n",
        "    cnnLayers += [layers.MaxPooling2D((maxPoolParams,maxPoolParams))]\n",
        "    cnnLayers += [layers.Dropout(dropout)]\n",
        "\n",
        "  annLayers = []\n",
        "  for ls in annParams:\n",
        "    annLayers += [layers.Dense(ls,activation=annFunc)]\n",
        "    annLayers += [layers.Dropout(dropout)]\n",
        "  annLayers += [layers.Dense(5,activation='softmax')]\n",
        "\n",
        "  allLayers = cnnLayers+[layers.Flatten()]+annLayers\n",
        "\n",
        "  model = Sequential(allLayers)\n",
        "  model.compile(optimizer=Adam(),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "  \n",
        "\n",
        "\n",
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=11,\n",
        "    factor=3,\n",
        "    directory='Flower',\n",
        "    project_name='Factor3Epoch11'\n",
        ")\n",
        "\n",
        "tuner.search(\n",
        "    train,\n",
        "    validation_data = val\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2939 images belonging to 5 classes.\n",
            "Found 731 images belonging to 5 classes.\n",
            "INFO:tensorflow:Reloading Oracle from existing project Flower/Factor3Epoch11/oracle.json\n",
            "INFO:tensorflow:Reloading Tuner from Flower/Factor3Epoch11/tuner0.json\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-823c8024eaed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_models\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m   \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   1344\u001b[0m     \"\"\"\n\u001b[1;32m   1345\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[1;32m   1347\u001b[0m                        \u001b[0;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m                        \u001b[0;34m'`fit()` with some data, or specify '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ovmpwkxz5Nf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c742041-f402-4d79-dbf1-bdd628be69b2"
      },
      "source": [
        "'''\n",
        "Training the 5 best models from Hyperband\n",
        "Goal: Hyperband has found a few models that are worth looking into.\n",
        "      Train these models further to see which one is worth training.\n",
        "'''\n",
        "\n",
        "i = 0\n",
        "data = []\n",
        "for m in tuner.get_best_models(num_models=5):\n",
        "  i+=1\n",
        "  data.append(m.fit(\n",
        "    train,\n",
        "    validation_data = val,\n",
        "    epochs=50))\n",
        "  tf.keras.models.save_model(m,'./tunerbestmodels_e50_'+str(i))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "Epoch 1/50\n",
            "92/92 [==============================] - 28s 304ms/step - loss: 1.4213 - accuracy: 0.4753 - val_loss: 1.3846 - val_accuracy: 0.5048\n",
            "Epoch 2/50\n",
            "92/92 [==============================] - 27s 298ms/step - loss: 1.4171 - accuracy: 0.4767 - val_loss: 1.3797 - val_accuracy: 0.5185\n",
            "Epoch 3/50\n",
            "92/92 [==============================] - 27s 298ms/step - loss: 1.4027 - accuracy: 0.4900 - val_loss: 1.3608 - val_accuracy: 0.5376\n",
            "Epoch 4/50\n",
            "92/92 [==============================] - 28s 300ms/step - loss: 1.4027 - accuracy: 0.4968 - val_loss: 1.3639 - val_accuracy: 0.5390\n",
            "Epoch 5/50\n",
            "92/92 [==============================] - 27s 299ms/step - loss: 1.3976 - accuracy: 0.4985 - val_loss: 1.3699 - val_accuracy: 0.5308\n",
            "Epoch 6/50\n",
            "92/92 [==============================] - 27s 297ms/step - loss: 1.4024 - accuracy: 0.4893 - val_loss: 1.3560 - val_accuracy: 0.5486\n",
            "Epoch 7/50\n",
            "92/92 [==============================] - 28s 301ms/step - loss: 1.4012 - accuracy: 0.4903 - val_loss: 1.3586 - val_accuracy: 0.5417\n",
            "Epoch 8/50\n",
            "92/92 [==============================] - 27s 299ms/step - loss: 1.3901 - accuracy: 0.5026 - val_loss: 1.3540 - val_accuracy: 0.5431\n",
            "Epoch 9/50\n",
            "92/92 [==============================] - 28s 299ms/step - loss: 1.3863 - accuracy: 0.5179 - val_loss: 1.3617 - val_accuracy: 0.5308\n",
            "Epoch 10/50\n",
            "92/92 [==============================] - 27s 299ms/step - loss: 1.3968 - accuracy: 0.5046 - val_loss: 1.3757 - val_accuracy: 0.5280\n",
            "Epoch 11/50\n",
            "92/92 [==============================] - 28s 304ms/step - loss: 1.3931 - accuracy: 0.5032 - val_loss: 1.3361 - val_accuracy: 0.5595\n",
            "Epoch 12/50\n",
            "92/92 [==============================] - 28s 300ms/step - loss: 1.3835 - accuracy: 0.5172 - val_loss: 1.3672 - val_accuracy: 0.5321\n",
            "Epoch 13/50\n",
            "92/92 [==============================] - 28s 300ms/step - loss: 1.3885 - accuracy: 0.5175 - val_loss: 1.3565 - val_accuracy: 0.5445\n",
            "Epoch 14/50\n",
            "92/92 [==============================] - 28s 301ms/step - loss: 1.3811 - accuracy: 0.5175 - val_loss: 1.3617 - val_accuracy: 0.5404\n",
            "Epoch 15/50\n",
            "92/92 [==============================] - 28s 302ms/step - loss: 1.3786 - accuracy: 0.5185 - val_loss: 1.3545 - val_accuracy: 0.5527\n",
            "Epoch 16/50\n",
            "92/92 [==============================] - 28s 302ms/step - loss: 1.3683 - accuracy: 0.5356 - val_loss: 1.3539 - val_accuracy: 0.5445\n",
            "Epoch 17/50\n",
            "92/92 [==============================] - 28s 302ms/step - loss: 1.3772 - accuracy: 0.5192 - val_loss: 1.3642 - val_accuracy: 0.5308\n",
            "Epoch 18/50\n",
            "92/92 [==============================] - 28s 300ms/step - loss: 1.3780 - accuracy: 0.5175 - val_loss: 1.3487 - val_accuracy: 0.5568\n",
            "Epoch 19/50\n",
            "92/92 [==============================] - 28s 301ms/step - loss: 1.3638 - accuracy: 0.5352 - val_loss: 1.3600 - val_accuracy: 0.5417\n",
            "Epoch 20/50\n",
            "92/92 [==============================] - 28s 300ms/step - loss: 1.3651 - accuracy: 0.5345 - val_loss: 1.3522 - val_accuracy: 0.5472\n",
            "Epoch 21/50\n",
            "92/92 [==============================] - 28s 301ms/step - loss: 1.3612 - accuracy: 0.5342 - val_loss: 1.3749 - val_accuracy: 0.5239\n",
            "Epoch 22/50\n",
            "92/92 [==============================] - 28s 301ms/step - loss: 1.3627 - accuracy: 0.5352 - val_loss: 1.3480 - val_accuracy: 0.5554\n",
            "Epoch 23/50\n",
            "92/92 [==============================] - 28s 300ms/step - loss: 1.3565 - accuracy: 0.5464 - val_loss: 1.3416 - val_accuracy: 0.5622\n",
            "Epoch 24/50\n",
            "92/92 [==============================] - 28s 300ms/step - loss: 1.3708 - accuracy: 0.5291 - val_loss: 1.3825 - val_accuracy: 0.5130\n",
            "Epoch 25/50\n",
            "92/92 [==============================] - 27s 297ms/step - loss: 1.3664 - accuracy: 0.5335 - val_loss: 1.3831 - val_accuracy: 0.5144\n",
            "Epoch 26/50\n",
            "92/92 [==============================] - 27s 296ms/step - loss: 1.3882 - accuracy: 0.5083 - val_loss: 1.4410 - val_accuracy: 0.4624\n",
            "Epoch 27/50\n",
            "92/92 [==============================] - 27s 297ms/step - loss: 1.3628 - accuracy: 0.5369 - val_loss: 1.3335 - val_accuracy: 0.5663\n",
            "Epoch 28/50\n",
            "92/92 [==============================] - 27s 296ms/step - loss: 1.3715 - accuracy: 0.5271 - val_loss: 1.3472 - val_accuracy: 0.5568\n",
            "Epoch 29/50\n",
            "92/92 [==============================] - 27s 297ms/step - loss: 1.3519 - accuracy: 0.5519 - val_loss: 1.3424 - val_accuracy: 0.5554\n",
            "Epoch 30/50\n",
            "92/92 [==============================] - 27s 297ms/step - loss: 1.3510 - accuracy: 0.5488 - val_loss: 1.3358 - val_accuracy: 0.5663\n",
            "Epoch 31/50\n",
            "92/92 [==============================] - 27s 296ms/step - loss: 1.3568 - accuracy: 0.5390 - val_loss: 1.3276 - val_accuracy: 0.5718\n",
            "Epoch 32/50\n",
            "92/92 [==============================] - 27s 296ms/step - loss: 1.3456 - accuracy: 0.5526 - val_loss: 1.3448 - val_accuracy: 0.5595\n",
            "Epoch 33/50\n",
            "92/92 [==============================] - 27s 297ms/step - loss: 1.3600 - accuracy: 0.5427 - val_loss: 1.3477 - val_accuracy: 0.5486\n",
            "Epoch 34/50\n",
            "92/92 [==============================] - 27s 297ms/step - loss: 1.3399 - accuracy: 0.5601 - val_loss: 1.3380 - val_accuracy: 0.5636\n",
            "Epoch 35/50\n",
            "92/92 [==============================] - 27s 294ms/step - loss: 1.3504 - accuracy: 0.5495 - val_loss: 1.3429 - val_accuracy: 0.5677\n",
            "Epoch 36/50\n",
            "92/92 [==============================] - 27s 296ms/step - loss: 1.3473 - accuracy: 0.5550 - val_loss: 1.3418 - val_accuracy: 0.5581\n",
            "Epoch 37/50\n",
            "92/92 [==============================] - 27s 295ms/step - loss: 1.3377 - accuracy: 0.5624 - val_loss: 1.3230 - val_accuracy: 0.5787\n",
            "Epoch 38/50\n",
            "92/92 [==============================] - 27s 296ms/step - loss: 1.3572 - accuracy: 0.5417 - val_loss: 1.3209 - val_accuracy: 0.5787\n",
            "Epoch 39/50\n",
            "92/92 [==============================] - 27s 295ms/step - loss: 1.3521 - accuracy: 0.5430 - val_loss: 1.3261 - val_accuracy: 0.5746\n",
            "Epoch 40/50\n",
            "92/92 [==============================] - 27s 295ms/step - loss: 1.3442 - accuracy: 0.5567 - val_loss: 1.3339 - val_accuracy: 0.5663\n",
            "Epoch 41/50\n",
            "92/92 [==============================] - 27s 295ms/step - loss: 1.3639 - accuracy: 0.5352 - val_loss: 1.3321 - val_accuracy: 0.5650\n",
            "Epoch 42/50\n",
            "92/92 [==============================] - 27s 295ms/step - loss: 1.3359 - accuracy: 0.5658 - val_loss: 1.3286 - val_accuracy: 0.5718\n",
            "Epoch 43/50\n",
            "92/92 [==============================] - 28s 302ms/step - loss: 1.3302 - accuracy: 0.5747 - val_loss: 1.3217 - val_accuracy: 0.5759\n",
            "Epoch 44/50\n",
            "92/92 [==============================] - 28s 300ms/step - loss: 1.3499 - accuracy: 0.5498 - val_loss: 1.3339 - val_accuracy: 0.5663\n",
            "Epoch 45/50\n",
            "92/92 [==============================] - 28s 301ms/step - loss: 1.3436 - accuracy: 0.5532 - val_loss: 1.3073 - val_accuracy: 0.5869\n",
            "Epoch 46/50\n",
            "92/92 [==============================] - 27s 296ms/step - loss: 1.3438 - accuracy: 0.5550 - val_loss: 1.3195 - val_accuracy: 0.5855\n",
            "Epoch 47/50\n",
            "92/92 [==============================] - 27s 295ms/step - loss: 1.3476 - accuracy: 0.5526 - val_loss: 1.3143 - val_accuracy: 0.5896\n",
            "Epoch 48/50\n",
            "92/92 [==============================] - 27s 296ms/step - loss: 1.3418 - accuracy: 0.5563 - val_loss: 1.3430 - val_accuracy: 0.5581\n",
            "Epoch 49/50\n",
            "92/92 [==============================] - 27s 295ms/step - loss: 1.3368 - accuracy: 0.5631 - val_loss: 1.3044 - val_accuracy: 0.5964\n",
            "Epoch 50/50\n",
            "92/92 [==============================] - 27s 296ms/step - loss: 1.3409 - accuracy: 0.5584 - val_loss: 1.3530 - val_accuracy: 0.5486\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: ./tunerbestmodels_e50_1/assets\n",
            "Epoch 1/50\n",
            "92/92 [==============================] - 27s 295ms/step - loss: 1.3760 - accuracy: 0.5236 - val_loss: 1.3631 - val_accuracy: 0.5431\n",
            "Epoch 2/50\n",
            "92/92 [==============================] - 27s 296ms/step - loss: 1.3623 - accuracy: 0.5420 - val_loss: 1.3703 - val_accuracy: 0.5294\n",
            "Epoch 3/50\n",
            "92/92 [==============================] - 27s 298ms/step - loss: 1.3548 - accuracy: 0.5434 - val_loss: 1.3445 - val_accuracy: 0.5568\n",
            "Epoch 4/50\n",
            "92/92 [==============================] - 27s 295ms/step - loss: 1.3553 - accuracy: 0.5427 - val_loss: 1.3591 - val_accuracy: 0.5499\n",
            "Epoch 5/50\n",
            "92/92 [==============================] - 27s 296ms/step - loss: 1.3535 - accuracy: 0.5461 - val_loss: 1.3706 - val_accuracy: 0.5390\n",
            "Epoch 6/50\n",
            "92/92 [==============================] - 27s 298ms/step - loss: 1.3499 - accuracy: 0.5515 - val_loss: 1.3581 - val_accuracy: 0.5335\n",
            "Epoch 7/50\n",
            "92/92 [==============================] - 27s 297ms/step - loss: 1.3470 - accuracy: 0.5567 - val_loss: 1.3296 - val_accuracy: 0.5773\n",
            "Epoch 8/50\n",
            "92/92 [==============================] - 27s 297ms/step - loss: 1.3511 - accuracy: 0.5488 - val_loss: 1.3652 - val_accuracy: 0.5308\n",
            "Epoch 9/50\n",
            "92/92 [==============================] - 27s 295ms/step - loss: 1.3451 - accuracy: 0.5502 - val_loss: 1.3905 - val_accuracy: 0.5034\n",
            "Epoch 10/50\n",
            "92/92 [==============================] - 27s 295ms/step - loss: 1.3394 - accuracy: 0.5563 - val_loss: 1.3412 - val_accuracy: 0.5609\n",
            "Epoch 11/50\n",
            "92/92 [==============================] - 27s 295ms/step - loss: 1.3426 - accuracy: 0.5594 - val_loss: 1.3277 - val_accuracy: 0.5773\n",
            "Epoch 12/50\n",
            "92/92 [==============================] - 27s 294ms/step - loss: 1.3288 - accuracy: 0.5713 - val_loss: 1.3183 - val_accuracy: 0.5855\n",
            "Epoch 13/50\n",
            "92/92 [==============================] - 27s 294ms/step - loss: 1.3353 - accuracy: 0.5648 - val_loss: 1.3252 - val_accuracy: 0.5773\n",
            "Epoch 14/50\n",
            "92/92 [==============================] - 27s 294ms/step - loss: 1.3294 - accuracy: 0.5747 - val_loss: 1.3336 - val_accuracy: 0.5650\n",
            "Epoch 15/50\n",
            "92/92 [==============================] - 28s 300ms/step - loss: 1.3262 - accuracy: 0.5713 - val_loss: 1.3180 - val_accuracy: 0.5814\n",
            "Epoch 16/50\n",
            "92/92 [==============================] - 28s 303ms/step - loss: 1.3204 - accuracy: 0.5815 - val_loss: 1.3172 - val_accuracy: 0.5855\n",
            "Epoch 17/50\n",
            "92/92 [==============================] - 28s 304ms/step - loss: 1.3358 - accuracy: 0.5645 - val_loss: 1.3180 - val_accuracy: 0.5841\n",
            "Epoch 18/50\n",
            "92/92 [==============================] - 28s 302ms/step - loss: 1.3262 - accuracy: 0.5750 - val_loss: 1.3088 - val_accuracy: 0.6019\n",
            "Epoch 19/50\n",
            "92/92 [==============================] - 28s 301ms/step - loss: 1.3269 - accuracy: 0.5774 - val_loss: 1.3063 - val_accuracy: 0.6019\n",
            "Epoch 20/50\n",
            "92/92 [==============================] - 28s 302ms/step - loss: 1.3195 - accuracy: 0.5846 - val_loss: 1.3157 - val_accuracy: 0.5882\n",
            "Epoch 21/50\n",
            "92/92 [==============================] - 28s 303ms/step - loss: 1.3190 - accuracy: 0.5808 - val_loss: 1.3115 - val_accuracy: 0.5896\n",
            "Epoch 22/50\n",
            "92/92 [==============================] - 28s 301ms/step - loss: 1.3301 - accuracy: 0.5713 - val_loss: 1.3186 - val_accuracy: 0.5746\n",
            "Epoch 23/50\n",
            "92/92 [==============================] - 28s 299ms/step - loss: 1.3211 - accuracy: 0.5812 - val_loss: 1.3129 - val_accuracy: 0.5869\n",
            "Epoch 24/50\n",
            "92/92 [==============================] - 27s 299ms/step - loss: 1.3119 - accuracy: 0.5903 - val_loss: 1.3130 - val_accuracy: 0.5882\n",
            "Epoch 25/50\n",
            "92/92 [==============================] - 28s 299ms/step - loss: 1.3132 - accuracy: 0.5866 - val_loss: 1.3087 - val_accuracy: 0.6019\n",
            "Epoch 26/50\n",
            "92/92 [==============================] - 27s 296ms/step - loss: 1.3048 - accuracy: 0.5975 - val_loss: 1.3289 - val_accuracy: 0.5705\n",
            "Epoch 27/50\n",
            "92/92 [==============================] - 27s 297ms/step - loss: 1.3248 - accuracy: 0.5760 - val_loss: 1.3299 - val_accuracy: 0.5759\n",
            "Epoch 28/50\n",
            "92/92 [==============================] - 28s 299ms/step - loss: 1.3128 - accuracy: 0.5886 - val_loss: 1.2992 - val_accuracy: 0.6101\n",
            "Epoch 29/50\n",
            "92/92 [==============================] - 27s 298ms/step - loss: 1.3159 - accuracy: 0.5856 - val_loss: 1.3107 - val_accuracy: 0.5882\n",
            "Epoch 30/50\n",
            "92/92 [==============================] - 27s 298ms/step - loss: 1.3139 - accuracy: 0.5863 - val_loss: 1.2904 - val_accuracy: 0.6129\n",
            "Epoch 31/50\n",
            "92/92 [==============================] - 27s 296ms/step - loss: 1.3081 - accuracy: 0.5914 - val_loss: 1.2950 - val_accuracy: 0.6047\n",
            "Epoch 32/50\n",
            "92/92 [==============================] - 27s 297ms/step - loss: 1.3039 - accuracy: 0.5958 - val_loss: 1.3190 - val_accuracy: 0.5869\n",
            "Epoch 33/50\n",
            "92/92 [==============================] - 27s 297ms/step - loss: 1.3113 - accuracy: 0.5910 - val_loss: 1.2946 - val_accuracy: 0.6156\n",
            "Epoch 34/50\n",
            "92/92 [==============================] - 27s 297ms/step - loss: 1.2955 - accuracy: 0.6050 - val_loss: 1.3252 - val_accuracy: 0.5746\n",
            "Epoch 35/50\n",
            "92/92 [==============================] - 27s 298ms/step - loss: 1.3112 - accuracy: 0.5900 - val_loss: 1.3034 - val_accuracy: 0.6005\n",
            "Epoch 36/50\n",
            "92/92 [==============================] - 27s 298ms/step - loss: 1.3034 - accuracy: 0.5995 - val_loss: 1.3050 - val_accuracy: 0.5964\n",
            "Epoch 37/50\n",
            "92/92 [==============================] - 27s 298ms/step - loss: 1.3134 - accuracy: 0.5883 - val_loss: 1.3019 - val_accuracy: 0.6005\n",
            "Epoch 38/50\n",
            "92/92 [==============================] - 27s 296ms/step - loss: 1.2957 - accuracy: 0.6050 - val_loss: 1.3009 - val_accuracy: 0.5964\n",
            "Epoch 39/50\n",
            "92/92 [==============================] - 27s 298ms/step - loss: 1.2992 - accuracy: 0.6026 - val_loss: 1.3031 - val_accuracy: 0.5964\n",
            "Epoch 40/50\n",
            "92/92 [==============================] - 27s 299ms/step - loss: 1.2970 - accuracy: 0.6016 - val_loss: 1.3152 - val_accuracy: 0.5855\n",
            "Epoch 41/50\n",
            "92/92 [==============================] - 27s 297ms/step - loss: 1.3174 - accuracy: 0.5832 - val_loss: 1.3148 - val_accuracy: 0.5923\n",
            "Epoch 42/50\n",
            "92/92 [==============================] - 27s 298ms/step - loss: 1.3073 - accuracy: 0.5934 - val_loss: 1.2998 - val_accuracy: 0.6074\n",
            "Epoch 43/50\n",
            "92/92 [==============================] - 27s 297ms/step - loss: 1.3058 - accuracy: 0.5988 - val_loss: 1.2984 - val_accuracy: 0.6033\n",
            "Epoch 44/50\n",
            "92/92 [==============================] - 28s 299ms/step - loss: 1.3015 - accuracy: 0.5995 - val_loss: 1.3123 - val_accuracy: 0.5855\n",
            "Epoch 45/50\n",
            "92/92 [==============================] - 29s 310ms/step - loss: 1.3032 - accuracy: 0.5961 - val_loss: 1.2910 - val_accuracy: 0.6101\n",
            "Epoch 46/50\n",
            "92/92 [==============================] - 27s 296ms/step - loss: 1.3068 - accuracy: 0.5948 - val_loss: 1.3158 - val_accuracy: 0.5814\n",
            "Epoch 47/50\n",
            "92/92 [==============================] - 27s 295ms/step - loss: 1.3082 - accuracy: 0.5920 - val_loss: 1.2866 - val_accuracy: 0.6170\n",
            "Epoch 48/50\n",
            "92/92 [==============================] - 27s 295ms/step - loss: 1.2980 - accuracy: 0.6043 - val_loss: 1.3104 - val_accuracy: 0.5896\n",
            "Epoch 49/50\n",
            "92/92 [==============================] - 27s 294ms/step - loss: 1.2971 - accuracy: 0.6046 - val_loss: 1.3147 - val_accuracy: 0.5937\n",
            "Epoch 50/50\n",
            "92/92 [==============================] - 27s 293ms/step - loss: 1.2981 - accuracy: 0.6043 - val_loss: 1.3248 - val_accuracy: 0.5746\n",
            "INFO:tensorflow:Assets written to: ./tunerbestmodels_e50_2/assets\n",
            "Epoch 1/50\n",
            "92/92 [==============================] - 28s 302ms/step - loss: 1.3919 - accuracy: 0.5107 - val_loss: 1.3917 - val_accuracy: 0.5075\n",
            "Epoch 2/50\n",
            "92/92 [==============================] - 28s 299ms/step - loss: 1.3815 - accuracy: 0.5192 - val_loss: 1.3763 - val_accuracy: 0.5226\n",
            "Epoch 3/50\n",
            "92/92 [==============================] - 28s 300ms/step - loss: 1.3839 - accuracy: 0.5172 - val_loss: 1.4109 - val_accuracy: 0.4870\n",
            "Epoch 4/50\n",
            "92/92 [==============================] - 28s 299ms/step - loss: 1.3984 - accuracy: 0.5022 - val_loss: 1.3964 - val_accuracy: 0.5048\n",
            "Epoch 5/50\n",
            "92/92 [==============================] - 28s 307ms/step - loss: 1.3865 - accuracy: 0.5141 - val_loss: 1.5096 - val_accuracy: 0.3830\n",
            "Epoch 6/50\n",
            "92/92 [==============================] - 28s 307ms/step - loss: 1.3738 - accuracy: 0.5294 - val_loss: 1.3711 - val_accuracy: 0.5321\n",
            "Epoch 7/50\n",
            "92/92 [==============================] - 28s 306ms/step - loss: 1.3716 - accuracy: 0.5308 - val_loss: 1.3877 - val_accuracy: 0.5144\n",
            "Epoch 8/50\n",
            "92/92 [==============================] - 28s 308ms/step - loss: 1.3810 - accuracy: 0.5230 - val_loss: 1.4011 - val_accuracy: 0.5048\n",
            "Epoch 9/50\n",
            "92/92 [==============================] - 28s 308ms/step - loss: 1.3830 - accuracy: 0.5189 - val_loss: 1.4337 - val_accuracy: 0.4706\n",
            "Epoch 10/50\n",
            "92/92 [==============================] - 28s 307ms/step - loss: 1.4697 - accuracy: 0.4294 - val_loss: 1.6038 - val_accuracy: 0.3010\n",
            "Epoch 11/50\n",
            "92/92 [==============================] - 28s 306ms/step - loss: 1.5322 - accuracy: 0.3695 - val_loss: 1.5083 - val_accuracy: 0.3953\n",
            "Epoch 12/50\n",
            "92/92 [==============================] - 28s 308ms/step - loss: 1.4972 - accuracy: 0.4049 - val_loss: 1.5045 - val_accuracy: 0.3981\n",
            "Epoch 13/50\n",
            "92/92 [==============================] - 28s 306ms/step - loss: 1.3973 - accuracy: 0.5049 - val_loss: 1.3662 - val_accuracy: 0.5404\n",
            "Epoch 14/50\n",
            "92/92 [==============================] - 28s 308ms/step - loss: 1.3624 - accuracy: 0.5403 - val_loss: 1.3769 - val_accuracy: 0.5239\n",
            "Epoch 15/50\n",
            "92/92 [==============================] - 28s 308ms/step - loss: 1.3603 - accuracy: 0.5444 - val_loss: 1.3861 - val_accuracy: 0.5212\n",
            "Epoch 16/50\n",
            "92/92 [==============================] - 28s 306ms/step - loss: 1.3648 - accuracy: 0.5366 - val_loss: 1.3964 - val_accuracy: 0.5062\n",
            "Epoch 17/50\n",
            "92/92 [==============================] - 28s 306ms/step - loss: 1.3600 - accuracy: 0.5437 - val_loss: 1.4048 - val_accuracy: 0.4966\n",
            "Epoch 18/50\n",
            "92/92 [==============================] - 28s 308ms/step - loss: 1.3825 - accuracy: 0.5209 - val_loss: 1.3891 - val_accuracy: 0.5130\n",
            "Epoch 19/50\n",
            "92/92 [==============================] - 28s 307ms/step - loss: 1.3644 - accuracy: 0.5379 - val_loss: 1.3834 - val_accuracy: 0.5226\n",
            "Epoch 20/50\n",
            "92/92 [==============================] - 28s 308ms/step - loss: 1.3597 - accuracy: 0.5427 - val_loss: 1.3930 - val_accuracy: 0.5103\n",
            "Epoch 21/50\n",
            "92/92 [==============================] - 28s 307ms/step - loss: 1.4040 - accuracy: 0.5005 - val_loss: 1.4287 - val_accuracy: 0.4733\n",
            "Epoch 22/50\n",
            "92/92 [==============================] - 28s 306ms/step - loss: 1.3608 - accuracy: 0.5424 - val_loss: 1.3700 - val_accuracy: 0.5335\n",
            "Epoch 23/50\n",
            "92/92 [==============================] - 28s 309ms/step - loss: 1.3593 - accuracy: 0.5441 - val_loss: 1.3758 - val_accuracy: 0.5294\n",
            "Epoch 24/50\n",
            "92/92 [==============================] - 28s 307ms/step - loss: 1.3537 - accuracy: 0.5509 - val_loss: 1.3754 - val_accuracy: 0.5267\n",
            "Epoch 25/50\n",
            "92/92 [==============================] - 28s 308ms/step - loss: 1.3508 - accuracy: 0.5526 - val_loss: 1.3737 - val_accuracy: 0.5267\n",
            "Epoch 26/50\n",
            "92/92 [==============================] - 28s 308ms/step - loss: 1.3592 - accuracy: 0.5434 - val_loss: 1.3710 - val_accuracy: 0.5321\n",
            "Epoch 27/50\n",
            "92/92 [==============================] - 28s 307ms/step - loss: 1.3622 - accuracy: 0.5410 - val_loss: 1.4204 - val_accuracy: 0.4815\n",
            "Epoch 28/50\n",
            "92/92 [==============================] - 28s 308ms/step - loss: 1.3720 - accuracy: 0.5322 - val_loss: 1.3646 - val_accuracy: 0.5376\n",
            "Epoch 29/50\n",
            "92/92 [==============================] - 28s 307ms/step - loss: 1.3485 - accuracy: 0.5529 - val_loss: 1.3930 - val_accuracy: 0.5116\n",
            "Epoch 30/50\n",
            "92/92 [==============================] - 28s 308ms/step - loss: 1.4218 - accuracy: 0.4791 - val_loss: 1.3749 - val_accuracy: 0.5267\n",
            "Epoch 31/50\n",
            "92/92 [==============================] - 28s 305ms/step - loss: 1.3621 - accuracy: 0.5427 - val_loss: 1.3813 - val_accuracy: 0.5212\n",
            "Epoch 32/50\n",
            "92/92 [==============================] - 28s 305ms/step - loss: 1.3749 - accuracy: 0.5284 - val_loss: 1.4285 - val_accuracy: 0.4747\n",
            "Epoch 33/50\n",
            "92/92 [==============================] - 28s 306ms/step - loss: 1.3722 - accuracy: 0.5318 - val_loss: 1.3797 - val_accuracy: 0.5185\n",
            "Epoch 34/50\n",
            "92/92 [==============================] - 28s 309ms/step - loss: 1.3644 - accuracy: 0.5373 - val_loss: 1.3606 - val_accuracy: 0.5431\n",
            "Epoch 35/50\n",
            "92/92 [==============================] - 28s 305ms/step - loss: 1.3568 - accuracy: 0.5464 - val_loss: 1.3604 - val_accuracy: 0.5445\n",
            "Epoch 36/50\n",
            "92/92 [==============================] - 28s 307ms/step - loss: 1.3540 - accuracy: 0.5485 - val_loss: 1.4186 - val_accuracy: 0.4829\n",
            "Epoch 37/50\n",
            "92/92 [==============================] - 28s 306ms/step - loss: 1.3695 - accuracy: 0.5332 - val_loss: 1.3810 - val_accuracy: 0.5226\n",
            "Epoch 38/50\n",
            "92/92 [==============================] - 28s 305ms/step - loss: 1.3595 - accuracy: 0.5441 - val_loss: 1.3724 - val_accuracy: 0.5308\n",
            "Epoch 39/50\n",
            "92/92 [==============================] - 28s 305ms/step - loss: 1.3535 - accuracy: 0.5495 - val_loss: 1.3611 - val_accuracy: 0.5390\n",
            "Epoch 40/50\n",
            "92/92 [==============================] - 28s 310ms/step - loss: 1.3554 - accuracy: 0.5458 - val_loss: 1.3598 - val_accuracy: 0.5445\n",
            "Epoch 41/50\n",
            "92/92 [==============================] - 28s 304ms/step - loss: 1.3650 - accuracy: 0.5386 - val_loss: 1.3660 - val_accuracy: 0.5363\n",
            "Epoch 42/50\n",
            "92/92 [==============================] - 28s 306ms/step - loss: 1.4118 - accuracy: 0.4893 - val_loss: 1.3618 - val_accuracy: 0.5431\n",
            "Epoch 43/50\n",
            "92/92 [==============================] - 28s 308ms/step - loss: 1.3603 - accuracy: 0.5437 - val_loss: 1.3771 - val_accuracy: 0.5294\n",
            "Epoch 44/50\n",
            "92/92 [==============================] - 28s 306ms/step - loss: 1.3446 - accuracy: 0.5587 - val_loss: 1.3862 - val_accuracy: 0.5171\n",
            "Epoch 45/50\n",
            "92/92 [==============================] - 28s 302ms/step - loss: 1.3746 - accuracy: 0.5288 - val_loss: 1.4027 - val_accuracy: 0.4993\n",
            "Epoch 46/50\n",
            "92/92 [==============================] - 28s 303ms/step - loss: 1.3669 - accuracy: 0.5366 - val_loss: 1.3946 - val_accuracy: 0.5089\n",
            "Epoch 47/50\n",
            "92/92 [==============================] - 28s 304ms/step - loss: 1.4329 - accuracy: 0.4702 - val_loss: 1.4270 - val_accuracy: 0.4774\n",
            "Epoch 48/50\n",
            "92/92 [==============================] - 28s 301ms/step - loss: 1.3992 - accuracy: 0.5036 - val_loss: 1.4330 - val_accuracy: 0.4679\n",
            "Epoch 49/50\n",
            "92/92 [==============================] - 27s 298ms/step - loss: 1.4235 - accuracy: 0.4798 - val_loss: 1.4092 - val_accuracy: 0.4966\n",
            "Epoch 50/50\n",
            "92/92 [==============================] - 27s 297ms/step - loss: 1.3726 - accuracy: 0.5315 - val_loss: 1.4128 - val_accuracy: 0.4911\n",
            "INFO:tensorflow:Assets written to: ./tunerbestmodels_e50_3/assets\n",
            "Epoch 1/50\n",
            "92/92 [==============================] - 27s 294ms/step - loss: 1.3966 - accuracy: 0.5070 - val_loss: 1.3865 - val_accuracy: 0.5198\n",
            "Epoch 2/50\n",
            "92/92 [==============================] - 27s 295ms/step - loss: 1.3877 - accuracy: 0.5162 - val_loss: 1.3896 - val_accuracy: 0.4979\n",
            "Epoch 3/50\n",
            "92/92 [==============================] - 27s 291ms/step - loss: 1.3844 - accuracy: 0.5189 - val_loss: 1.3697 - val_accuracy: 0.5321\n",
            "Epoch 4/50\n",
            "92/92 [==============================] - 27s 298ms/step - loss: 1.3868 - accuracy: 0.5145 - val_loss: 1.3814 - val_accuracy: 0.5294\n",
            "Epoch 5/50\n",
            "92/92 [==============================] - 27s 294ms/step - loss: 1.3744 - accuracy: 0.5311 - val_loss: 1.3736 - val_accuracy: 0.5335\n",
            "Epoch 6/50\n",
            "92/92 [==============================] - 27s 294ms/step - loss: 1.3713 - accuracy: 0.5294 - val_loss: 1.3700 - val_accuracy: 0.5294\n",
            "Epoch 7/50\n",
            "92/92 [==============================] - 27s 294ms/step - loss: 1.3651 - accuracy: 0.5383 - val_loss: 1.4076 - val_accuracy: 0.4979\n",
            "Epoch 8/50\n",
            "92/92 [==============================] - 27s 294ms/step - loss: 1.3586 - accuracy: 0.5427 - val_loss: 1.3568 - val_accuracy: 0.5472\n",
            "Epoch 9/50\n",
            "92/92 [==============================] - 27s 293ms/step - loss: 1.3537 - accuracy: 0.5485 - val_loss: 1.3820 - val_accuracy: 0.5499\n",
            "Epoch 10/50\n",
            "92/92 [==============================] - 27s 295ms/step - loss: 1.3608 - accuracy: 0.5410 - val_loss: 1.3708 - val_accuracy: 0.5431\n",
            "Epoch 11/50\n",
            "92/92 [==============================] - 27s 295ms/step - loss: 1.3609 - accuracy: 0.5403 - val_loss: 1.3699 - val_accuracy: 0.5404\n",
            "Epoch 12/50\n",
            "92/92 [==============================] - 27s 298ms/step - loss: 1.3606 - accuracy: 0.5478 - val_loss: 1.3611 - val_accuracy: 0.5458\n",
            "Epoch 13/50\n",
            "92/92 [==============================] - 27s 297ms/step - loss: 1.3583 - accuracy: 0.5420 - val_loss: 1.3549 - val_accuracy: 0.5472\n",
            "Epoch 14/50\n",
            "92/92 [==============================] - 27s 297ms/step - loss: 1.3537 - accuracy: 0.5539 - val_loss: 1.3567 - val_accuracy: 0.5431\n",
            "Epoch 15/50\n",
            "92/92 [==============================] - 27s 299ms/step - loss: 1.3615 - accuracy: 0.5386 - val_loss: 1.3607 - val_accuracy: 0.5417\n",
            "Epoch 16/50\n",
            "92/92 [==============================] - 28s 301ms/step - loss: 1.3570 - accuracy: 0.5512 - val_loss: 1.3939 - val_accuracy: 0.5212\n",
            "Epoch 17/50\n",
            "92/92 [==============================] - 28s 303ms/step - loss: 1.3600 - accuracy: 0.5420 - val_loss: 1.3696 - val_accuracy: 0.5335\n",
            "Epoch 18/50\n",
            "92/92 [==============================] - 27s 298ms/step - loss: 1.3541 - accuracy: 0.5485 - val_loss: 1.3854 - val_accuracy: 0.5294\n",
            "Epoch 19/50\n",
            "92/92 [==============================] - 27s 298ms/step - loss: 1.3495 - accuracy: 0.5546 - val_loss: 1.3748 - val_accuracy: 0.5267\n",
            "Epoch 20/50\n",
            "92/92 [==============================] - 27s 298ms/step - loss: 1.3479 - accuracy: 0.5546 - val_loss: 1.3470 - val_accuracy: 0.5499\n",
            "Epoch 21/50\n",
            "92/92 [==============================] - 27s 296ms/step - loss: 1.3604 - accuracy: 0.5427 - val_loss: 1.3691 - val_accuracy: 0.5349\n",
            "Epoch 22/50\n",
            "92/92 [==============================] - 28s 299ms/step - loss: 1.3479 - accuracy: 0.5550 - val_loss: 1.3486 - val_accuracy: 0.5540\n",
            "Epoch 23/50\n",
            "92/92 [==============================] - 27s 296ms/step - loss: 1.3402 - accuracy: 0.5604 - val_loss: 1.3627 - val_accuracy: 0.5376\n",
            "Epoch 24/50\n",
            "92/92 [==============================] - 28s 299ms/step - loss: 1.3427 - accuracy: 0.5594 - val_loss: 1.3580 - val_accuracy: 0.5472\n",
            "Epoch 25/50\n",
            "92/92 [==============================] - 27s 298ms/step - loss: 1.3578 - accuracy: 0.5447 - val_loss: 1.3484 - val_accuracy: 0.5554\n",
            "Epoch 26/50\n",
            "92/92 [==============================] - 27s 296ms/step - loss: 1.3502 - accuracy: 0.5509 - val_loss: 1.3489 - val_accuracy: 0.5568\n",
            "Epoch 27/50\n",
            "92/92 [==============================] - 27s 297ms/step - loss: 1.3476 - accuracy: 0.5498 - val_loss: 1.3754 - val_accuracy: 0.5363\n",
            "Epoch 28/50\n",
            "92/92 [==============================] - 28s 299ms/step - loss: 1.3393 - accuracy: 0.5624 - val_loss: 1.3431 - val_accuracy: 0.5581\n",
            "Epoch 29/50\n",
            "92/92 [==============================] - 27s 297ms/step - loss: 1.3413 - accuracy: 0.5628 - val_loss: 1.3444 - val_accuracy: 0.5595\n",
            "Epoch 30/50\n",
            "92/92 [==============================] - 27s 297ms/step - loss: 1.3510 - accuracy: 0.5492 - val_loss: 1.3669 - val_accuracy: 0.5363\n",
            "Epoch 31/50\n",
            "92/92 [==============================] - 27s 298ms/step - loss: 1.3457 - accuracy: 0.5515 - val_loss: 1.3474 - val_accuracy: 0.5486\n",
            "Epoch 32/50\n",
            "92/92 [==============================] - 27s 295ms/step - loss: 1.3348 - accuracy: 0.5669 - val_loss: 1.3406 - val_accuracy: 0.5622\n",
            "Epoch 33/50\n",
            "92/92 [==============================] - 27s 294ms/step - loss: 1.3429 - accuracy: 0.5618 - val_loss: 1.3626 - val_accuracy: 0.5417\n",
            "Epoch 34/50\n",
            "92/92 [==============================] - 27s 295ms/step - loss: 1.3413 - accuracy: 0.5618 - val_loss: 1.3305 - val_accuracy: 0.5677\n",
            "Epoch 35/50\n",
            "92/92 [==============================] - 27s 294ms/step - loss: 1.3408 - accuracy: 0.5618 - val_loss: 1.3588 - val_accuracy: 0.5445\n",
            "Epoch 36/50\n",
            "92/92 [==============================] - 27s 293ms/step - loss: 1.3359 - accuracy: 0.5669 - val_loss: 1.3442 - val_accuracy: 0.5581\n",
            "Epoch 37/50\n",
            "92/92 [==============================] - 27s 292ms/step - loss: 1.3475 - accuracy: 0.5560 - val_loss: 1.3530 - val_accuracy: 0.5581\n",
            "Epoch 38/50\n",
            "92/92 [==============================] - 27s 292ms/step - loss: 1.3417 - accuracy: 0.5624 - val_loss: 1.3549 - val_accuracy: 0.5499\n",
            "Epoch 39/50\n",
            "92/92 [==============================] - 27s 291ms/step - loss: 1.3366 - accuracy: 0.5658 - val_loss: 1.3355 - val_accuracy: 0.5691\n",
            "Epoch 40/50\n",
            "92/92 [==============================] - 27s 293ms/step - loss: 1.3366 - accuracy: 0.5658 - val_loss: 1.3589 - val_accuracy: 0.5486\n",
            "Epoch 41/50\n",
            "92/92 [==============================] - 27s 291ms/step - loss: 1.3370 - accuracy: 0.5648 - val_loss: 1.3464 - val_accuracy: 0.5609\n",
            "Epoch 42/50\n",
            "92/92 [==============================] - 27s 291ms/step - loss: 1.3424 - accuracy: 0.5577 - val_loss: 1.3431 - val_accuracy: 0.5622\n",
            "Epoch 43/50\n",
            "92/92 [==============================] - 27s 291ms/step - loss: 1.3351 - accuracy: 0.5675 - val_loss: 1.3503 - val_accuracy: 0.5540\n",
            "Epoch 44/50\n",
            "92/92 [==============================] - 27s 288ms/step - loss: 1.3307 - accuracy: 0.5737 - val_loss: 1.3493 - val_accuracy: 0.5540\n",
            "Epoch 45/50\n",
            "92/92 [==============================] - 27s 291ms/step - loss: 1.3240 - accuracy: 0.5774 - val_loss: 1.3291 - val_accuracy: 0.5705\n",
            "Epoch 46/50\n",
            "92/92 [==============================] - 27s 292ms/step - loss: 1.3321 - accuracy: 0.5720 - val_loss: 1.3258 - val_accuracy: 0.5787\n",
            "Epoch 47/50\n",
            "92/92 [==============================] - 27s 292ms/step - loss: 1.3237 - accuracy: 0.5788 - val_loss: 1.3534 - val_accuracy: 0.5472\n",
            "Epoch 48/50\n",
            "92/92 [==============================] - 27s 290ms/step - loss: 1.3417 - accuracy: 0.5580 - val_loss: 1.3390 - val_accuracy: 0.5622\n",
            "Epoch 49/50\n",
            "92/92 [==============================] - 27s 290ms/step - loss: 1.3375 - accuracy: 0.5635 - val_loss: 1.3436 - val_accuracy: 0.5554\n",
            "Epoch 50/50\n",
            "92/92 [==============================] - 27s 292ms/step - loss: 1.3353 - accuracy: 0.5672 - val_loss: 1.3706 - val_accuracy: 0.5321\n",
            "INFO:tensorflow:Assets written to: ./tunerbestmodels_e50_4/assets\n",
            "Epoch 1/50\n",
            "92/92 [==============================] - 27s 293ms/step - loss: 1.4308 - accuracy: 0.4753 - val_loss: 1.4136 - val_accuracy: 0.4856\n",
            "Epoch 2/50\n",
            "92/92 [==============================] - 27s 288ms/step - loss: 1.4276 - accuracy: 0.4750 - val_loss: 1.4066 - val_accuracy: 0.4884\n",
            "Epoch 3/50\n",
            "92/92 [==============================] - 27s 288ms/step - loss: 1.4238 - accuracy: 0.4760 - val_loss: 1.4172 - val_accuracy: 0.4856\n",
            "Epoch 4/50\n",
            "92/92 [==============================] - 26s 285ms/step - loss: 1.4244 - accuracy: 0.4767 - val_loss: 1.4063 - val_accuracy: 0.4925\n",
            "Epoch 5/50\n",
            "92/92 [==============================] - 27s 293ms/step - loss: 1.4249 - accuracy: 0.4801 - val_loss: 1.3897 - val_accuracy: 0.5280\n",
            "Epoch 6/50\n",
            "92/92 [==============================] - 26s 286ms/step - loss: 1.4193 - accuracy: 0.4879 - val_loss: 1.4191 - val_accuracy: 0.4843\n",
            "Epoch 7/50\n",
            "92/92 [==============================] - 26s 283ms/step - loss: 1.4227 - accuracy: 0.4750 - val_loss: 1.3942 - val_accuracy: 0.5062\n",
            "Epoch 8/50\n",
            "92/92 [==============================] - 26s 285ms/step - loss: 1.4113 - accuracy: 0.4906 - val_loss: 1.3927 - val_accuracy: 0.5116\n",
            "Epoch 9/50\n",
            "92/92 [==============================] - 26s 284ms/step - loss: 1.4117 - accuracy: 0.4923 - val_loss: 1.3859 - val_accuracy: 0.5171\n",
            "Epoch 10/50\n",
            "92/92 [==============================] - 26s 283ms/step - loss: 1.4054 - accuracy: 0.5029 - val_loss: 1.3757 - val_accuracy: 0.5335\n",
            "Epoch 11/50\n",
            "92/92 [==============================] - 26s 281ms/step - loss: 1.4036 - accuracy: 0.5063 - val_loss: 1.3859 - val_accuracy: 0.5075\n",
            "Epoch 12/50\n",
            "92/92 [==============================] - 26s 282ms/step - loss: 1.4039 - accuracy: 0.5009 - val_loss: 1.3669 - val_accuracy: 0.5458\n",
            "Epoch 13/50\n",
            "92/92 [==============================] - 26s 284ms/step - loss: 1.4088 - accuracy: 0.4978 - val_loss: 1.3876 - val_accuracy: 0.5130\n",
            "Epoch 14/50\n",
            "92/92 [==============================] - 26s 281ms/step - loss: 1.3955 - accuracy: 0.5107 - val_loss: 1.3678 - val_accuracy: 0.5349\n",
            "Epoch 15/50\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.3870 - accuracy: 0.5192 - val_loss: 1.3745 - val_accuracy: 0.5294\n",
            "Epoch 16/50\n",
            "92/92 [==============================] - 26s 277ms/step - loss: 1.3953 - accuracy: 0.5111 - val_loss: 1.3620 - val_accuracy: 0.5431\n",
            "Epoch 17/50\n",
            "92/92 [==============================] - 26s 282ms/step - loss: 1.3946 - accuracy: 0.5172 - val_loss: 1.3991 - val_accuracy: 0.4966\n",
            "Epoch 18/50\n",
            "92/92 [==============================] - 26s 281ms/step - loss: 1.3963 - accuracy: 0.5046 - val_loss: 1.3629 - val_accuracy: 0.5445\n",
            "Epoch 19/50\n",
            "92/92 [==============================] - 26s 282ms/step - loss: 1.3931 - accuracy: 0.5117 - val_loss: 1.3755 - val_accuracy: 0.5308\n",
            "Epoch 20/50\n",
            "92/92 [==============================] - 26s 282ms/step - loss: 1.3795 - accuracy: 0.5315 - val_loss: 1.3580 - val_accuracy: 0.5363\n",
            "Epoch 21/50\n",
            "92/92 [==============================] - 26s 279ms/step - loss: 1.3850 - accuracy: 0.5213 - val_loss: 1.3819 - val_accuracy: 0.5116\n",
            "Epoch 22/50\n",
            "92/92 [==============================] - 26s 279ms/step - loss: 1.3870 - accuracy: 0.5233 - val_loss: 1.4111 - val_accuracy: 0.4925\n",
            "Epoch 23/50\n",
            "92/92 [==============================] - 26s 282ms/step - loss: 1.3888 - accuracy: 0.5172 - val_loss: 1.4723 - val_accuracy: 0.4213\n",
            "Epoch 24/50\n",
            "92/92 [==============================] - 26s 278ms/step - loss: 1.4014 - accuracy: 0.5036 - val_loss: 1.3608 - val_accuracy: 0.5445\n",
            "Epoch 25/50\n",
            "92/92 [==============================] - 26s 282ms/step - loss: 1.3746 - accuracy: 0.5410 - val_loss: 1.3843 - val_accuracy: 0.5253\n",
            "Epoch 26/50\n",
            "92/92 [==============================] - 26s 279ms/step - loss: 1.3768 - accuracy: 0.5335 - val_loss: 1.3854 - val_accuracy: 0.5226\n",
            "Epoch 27/50\n",
            "92/92 [==============================] - 26s 279ms/step - loss: 1.3688 - accuracy: 0.5373 - val_loss: 1.3665 - val_accuracy: 0.5280\n",
            "Epoch 28/50\n",
            "92/92 [==============================] - 26s 284ms/step - loss: 1.3647 - accuracy: 0.5492 - val_loss: 1.3571 - val_accuracy: 0.5376\n",
            "Epoch 29/50\n",
            "92/92 [==============================] - 26s 283ms/step - loss: 1.3748 - accuracy: 0.5373 - val_loss: 1.3646 - val_accuracy: 0.5349\n",
            "Epoch 30/50\n",
            "92/92 [==============================] - 26s 280ms/step - loss: 1.3722 - accuracy: 0.5410 - val_loss: 1.3559 - val_accuracy: 0.5472\n",
            "Epoch 31/50\n",
            "92/92 [==============================] - 27s 291ms/step - loss: 1.3710 - accuracy: 0.5359 - val_loss: 1.3575 - val_accuracy: 0.5417\n",
            "Epoch 32/50\n",
            "92/92 [==============================] - 26s 287ms/step - loss: 1.3636 - accuracy: 0.5379 - val_loss: 1.3577 - val_accuracy: 0.5458\n",
            "Epoch 33/50\n",
            "92/92 [==============================] - 27s 290ms/step - loss: 1.3652 - accuracy: 0.5430 - val_loss: 1.3450 - val_accuracy: 0.5540\n",
            "Epoch 34/50\n",
            "92/92 [==============================] - 26s 285ms/step - loss: 1.3697 - accuracy: 0.5396 - val_loss: 1.3514 - val_accuracy: 0.5540\n",
            "Epoch 35/50\n",
            "92/92 [==============================] - 26s 281ms/step - loss: 1.3582 - accuracy: 0.5481 - val_loss: 1.3497 - val_accuracy: 0.5581\n",
            "Epoch 36/50\n",
            "92/92 [==============================] - 26s 282ms/step - loss: 1.4115 - accuracy: 0.4961 - val_loss: 1.5544 - val_accuracy: 0.3461\n",
            "Epoch 37/50\n",
            "92/92 [==============================] - 26s 284ms/step - loss: 1.3820 - accuracy: 0.5233 - val_loss: 1.3537 - val_accuracy: 0.5458\n",
            "Epoch 38/50\n",
            "92/92 [==============================] - 26s 278ms/step - loss: 1.3583 - accuracy: 0.5505 - val_loss: 1.3542 - val_accuracy: 0.5527\n",
            "Epoch 39/50\n",
            "92/92 [==============================] - 25s 277ms/step - loss: 1.3663 - accuracy: 0.5410 - val_loss: 1.3611 - val_accuracy: 0.5431\n",
            "Epoch 40/50\n",
            "92/92 [==============================] - 26s 278ms/step - loss: 1.3677 - accuracy: 0.5359 - val_loss: 1.3430 - val_accuracy: 0.5554\n",
            "Epoch 41/50\n",
            "92/92 [==============================] - 25s 277ms/step - loss: 1.3623 - accuracy: 0.5451 - val_loss: 1.3470 - val_accuracy: 0.5513\n",
            "Epoch 42/50\n",
            "92/92 [==============================] - 26s 277ms/step - loss: 1.3516 - accuracy: 0.5570 - val_loss: 1.3474 - val_accuracy: 0.5609\n",
            "Epoch 43/50\n",
            "92/92 [==============================] - 26s 278ms/step - loss: 1.3574 - accuracy: 0.5492 - val_loss: 1.3413 - val_accuracy: 0.5581\n",
            "Epoch 44/50\n",
            "92/92 [==============================] - 26s 278ms/step - loss: 1.3635 - accuracy: 0.5444 - val_loss: 1.3829 - val_accuracy: 0.5171\n",
            "Epoch 45/50\n",
            "92/92 [==============================] - 26s 278ms/step - loss: 1.3596 - accuracy: 0.5512 - val_loss: 1.3434 - val_accuracy: 0.5554\n",
            "Epoch 46/50\n",
            "92/92 [==============================] - 25s 277ms/step - loss: 1.3495 - accuracy: 0.5536 - val_loss: 1.3462 - val_accuracy: 0.5540\n",
            "Epoch 47/50\n",
            "92/92 [==============================] - 25s 276ms/step - loss: 1.3502 - accuracy: 0.5553 - val_loss: 1.3409 - val_accuracy: 0.5609\n",
            "Epoch 48/50\n",
            "92/92 [==============================] - 25s 277ms/step - loss: 1.3557 - accuracy: 0.5522 - val_loss: 1.3353 - val_accuracy: 0.5581\n",
            "Epoch 49/50\n",
            "92/92 [==============================] - 26s 279ms/step - loss: 1.3491 - accuracy: 0.5567 - val_loss: 1.3421 - val_accuracy: 0.5609\n",
            "Epoch 50/50\n",
            "92/92 [==============================] - 25s 277ms/step - loss: 1.3562 - accuracy: 0.5495 - val_loss: 1.3633 - val_accuracy: 0.5363\n",
            "INFO:tensorflow:Assets written to: ./tunerbestmodels_e50_5/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArrXvy9Z0qQ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "41d0728a-16ed-46d4-b38d-1a061ccc00f3"
      },
      "source": [
        "'''\n",
        "Data Plotting for the first round\n",
        "Goal: Find which models are best based on validation metrics.\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "df = pd.DataFrame()\n",
        "\n",
        "for i in range(0,5):\n",
        "  #df[['accuracy'+str(i)]] = pd.DataFrame(data[i].history)[['accuracy']]\n",
        "  #df[['loss'+str(i)]] = pd.DataFrame(data[i].history)[['loss']]\n",
        "  df[['val_accuracy'+str(i)]] = pd.DataFrame(data[i].history)[['val_accuracy']]\n",
        "  #df[['val_loss'+str(i)]] = pd.DataFrame(data[i].history)[['val_loss']]\n",
        "\n",
        "\n",
        "df.plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff013dd3d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCIWap-LYV8E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4ad82b95-35bf-4eb1-e0db-940e987f287a"
      },
      "source": [
        "'''\n",
        "Data Training for second rounds of training\n",
        "Goal: Train models that are best out of the 5 best models\n",
        "      from Hyperband.\n",
        "'''\n",
        "\n",
        "i=0\n",
        "data2 = []\n",
        "for m in [\n",
        "          tf.keras.models.load_model('./tunerbestmodels_e50_1'),\n",
        "          tf.keras.models.load_model('./tunerbestmodels_e50_2'),\n",
        "          tf.keras.models.load_model('./tunerbestmodels_e50_5'),\n",
        "          ]:\n",
        "  i+=1\n",
        "  data2.append(m.fit(\n",
        "    train,\n",
        "    validation_data = val,\n",
        "    epochs=50))\n",
        "  tf.keras.models.save_model(m,'./tunerbestmodels_e100_'+str(i))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "92/92 [==============================] - 26s 281ms/step - loss: 1.3380 - accuracy: 0.5635 - val_loss: 1.3294 - val_accuracy: 0.5718\n",
            "Epoch 2/50\n",
            "92/92 [==============================] - 25s 276ms/step - loss: 1.3473 - accuracy: 0.5529 - val_loss: 1.3235 - val_accuracy: 0.5787\n",
            "Epoch 3/50\n",
            "92/92 [==============================] - 25s 277ms/step - loss: 1.3332 - accuracy: 0.5669 - val_loss: 1.3133 - val_accuracy: 0.5923\n",
            "Epoch 4/50\n",
            "92/92 [==============================] - 26s 278ms/step - loss: 1.3381 - accuracy: 0.5614 - val_loss: 1.3314 - val_accuracy: 0.5718\n",
            "Epoch 5/50\n",
            "92/92 [==============================] - 26s 277ms/step - loss: 1.3404 - accuracy: 0.5611 - val_loss: 1.3389 - val_accuracy: 0.5595\n",
            "Epoch 6/50\n",
            "92/92 [==============================] - 25s 276ms/step - loss: 1.3285 - accuracy: 0.5689 - val_loss: 1.3301 - val_accuracy: 0.5677\n",
            "Epoch 7/50\n",
            "92/92 [==============================] - 25s 276ms/step - loss: 1.3565 - accuracy: 0.5413 - val_loss: 1.3098 - val_accuracy: 0.5910\n",
            "Epoch 8/50\n",
            "92/92 [==============================] - 25s 275ms/step - loss: 1.3458 - accuracy: 0.5502 - val_loss: 1.3157 - val_accuracy: 0.5787\n",
            "Epoch 9/50\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.3235 - accuracy: 0.5750 - val_loss: 1.3246 - val_accuracy: 0.5773\n",
            "Epoch 10/50\n",
            "92/92 [==============================] - 25s 276ms/step - loss: 1.3368 - accuracy: 0.5587 - val_loss: 1.3328 - val_accuracy: 0.5650\n",
            "Epoch 11/50\n",
            "92/92 [==============================] - 25s 276ms/step - loss: 1.3604 - accuracy: 0.5352 - val_loss: 1.3283 - val_accuracy: 0.5718\n",
            "Epoch 12/50\n",
            "92/92 [==============================] - 25s 275ms/step - loss: 1.3417 - accuracy: 0.5584 - val_loss: 1.3088 - val_accuracy: 0.5923\n",
            "Epoch 13/50\n",
            "92/92 [==============================] - 26s 280ms/step - loss: 1.3308 - accuracy: 0.5713 - val_loss: 1.3329 - val_accuracy: 0.5595\n",
            "Epoch 14/50\n",
            "92/92 [==============================] - 25s 277ms/step - loss: 1.3468 - accuracy: 0.5539 - val_loss: 1.3479 - val_accuracy: 0.5513\n",
            "Epoch 15/50\n",
            "92/92 [==============================] - 25s 276ms/step - loss: 1.3406 - accuracy: 0.5563 - val_loss: 1.3016 - val_accuracy: 0.5964\n",
            "Epoch 16/50\n",
            "92/92 [==============================] - 25s 277ms/step - loss: 1.3239 - accuracy: 0.5747 - val_loss: 1.3298 - val_accuracy: 0.5691\n",
            "Epoch 17/50\n",
            "92/92 [==============================] - 25s 276ms/step - loss: 1.3333 - accuracy: 0.5689 - val_loss: 1.3077 - val_accuracy: 0.5896\n",
            "Epoch 18/50\n",
            "92/92 [==============================] - 25s 275ms/step - loss: 1.3316 - accuracy: 0.5692 - val_loss: 1.3324 - val_accuracy: 0.5691\n",
            "Epoch 19/50\n",
            "92/92 [==============================] - 26s 278ms/step - loss: 1.3627 - accuracy: 0.5383 - val_loss: 1.3171 - val_accuracy: 0.5841\n",
            "Epoch 20/50\n",
            "92/92 [==============================] - 25s 276ms/step - loss: 1.3353 - accuracy: 0.5635 - val_loss: 1.3213 - val_accuracy: 0.5800\n",
            "Epoch 21/50\n",
            "92/92 [==============================] - 25s 276ms/step - loss: 1.3409 - accuracy: 0.5573 - val_loss: 1.3197 - val_accuracy: 0.5800\n",
            "Epoch 22/50\n",
            "92/92 [==============================] - 25s 275ms/step - loss: 1.3358 - accuracy: 0.5635 - val_loss: 1.3359 - val_accuracy: 0.5677\n",
            "Epoch 23/50\n",
            "92/92 [==============================] - 25s 275ms/step - loss: 1.3239 - accuracy: 0.5757 - val_loss: 1.4054 - val_accuracy: 0.4911\n",
            "Epoch 24/50\n",
            "92/92 [==============================] - 25s 275ms/step - loss: 1.3318 - accuracy: 0.5699 - val_loss: 1.3878 - val_accuracy: 0.5116\n",
            "Epoch 25/50\n",
            "92/92 [==============================] - 25s 277ms/step - loss: 1.3436 - accuracy: 0.5563 - val_loss: 1.3100 - val_accuracy: 0.5937\n",
            "Epoch 26/50\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.3354 - accuracy: 0.5618 - val_loss: 1.3242 - val_accuracy: 0.5800\n",
            "Epoch 27/50\n",
            "92/92 [==============================] - 25s 276ms/step - loss: 1.3350 - accuracy: 0.5679 - val_loss: 1.3276 - val_accuracy: 0.5787\n",
            "Epoch 28/50\n",
            "92/92 [==============================] - 25s 276ms/step - loss: 1.3266 - accuracy: 0.5720 - val_loss: 1.3234 - val_accuracy: 0.5800\n",
            "Epoch 29/50\n",
            "92/92 [==============================] - 25s 275ms/step - loss: 1.3321 - accuracy: 0.5706 - val_loss: 1.2907 - val_accuracy: 0.6115\n",
            "Epoch 30/50\n",
            "92/92 [==============================] - 25s 275ms/step - loss: 1.3233 - accuracy: 0.5675 - val_loss: 1.3012 - val_accuracy: 0.5964\n",
            "Epoch 31/50\n",
            "92/92 [==============================] - 25s 275ms/step - loss: 1.3144 - accuracy: 0.5863 - val_loss: 1.3000 - val_accuracy: 0.6047\n",
            "Epoch 32/50\n",
            "92/92 [==============================] - 26s 277ms/step - loss: 1.3218 - accuracy: 0.5805 - val_loss: 1.2865 - val_accuracy: 0.6129\n",
            "Epoch 33/50\n",
            "92/92 [==============================] - 25s 276ms/step - loss: 1.3346 - accuracy: 0.5641 - val_loss: 1.3220 - val_accuracy: 0.5800\n",
            "Epoch 34/50\n",
            "92/92 [==============================] - 25s 275ms/step - loss: 1.3203 - accuracy: 0.5801 - val_loss: 1.3000 - val_accuracy: 0.6019\n",
            "Epoch 35/50\n",
            "92/92 [==============================] - 25s 276ms/step - loss: 1.3250 - accuracy: 0.5760 - val_loss: 1.2972 - val_accuracy: 0.6019\n",
            "Epoch 36/50\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.3240 - accuracy: 0.5781 - val_loss: 1.3044 - val_accuracy: 0.5978\n",
            "Epoch 37/50\n",
            "92/92 [==============================] - 25s 276ms/step - loss: 1.3329 - accuracy: 0.5645 - val_loss: 1.3133 - val_accuracy: 0.5923\n",
            "Epoch 38/50\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.3356 - accuracy: 0.5662 - val_loss: 1.2946 - val_accuracy: 0.6101\n",
            "Epoch 39/50\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.3250 - accuracy: 0.5737 - val_loss: 1.3020 - val_accuracy: 0.6005\n",
            "Epoch 40/50\n",
            "92/92 [==============================] - 25s 275ms/step - loss: 1.3290 - accuracy: 0.5730 - val_loss: 1.3265 - val_accuracy: 0.5732\n",
            "Epoch 41/50\n",
            "92/92 [==============================] - 25s 276ms/step - loss: 1.3289 - accuracy: 0.5720 - val_loss: 1.3068 - val_accuracy: 0.5978\n",
            "Epoch 42/50\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.3230 - accuracy: 0.5740 - val_loss: 1.3032 - val_accuracy: 0.5978\n",
            "Epoch 43/50\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.3251 - accuracy: 0.5757 - val_loss: 1.2872 - val_accuracy: 0.6156\n",
            "Epoch 44/50\n",
            "92/92 [==============================] - 26s 279ms/step - loss: 1.3297 - accuracy: 0.5716 - val_loss: 1.3122 - val_accuracy: 0.5896\n",
            "Epoch 45/50\n",
            "92/92 [==============================] - 25s 276ms/step - loss: 1.3328 - accuracy: 0.5679 - val_loss: 1.3013 - val_accuracy: 0.5978\n",
            "Epoch 46/50\n",
            "92/92 [==============================] - 25s 275ms/step - loss: 1.3208 - accuracy: 0.5798 - val_loss: 1.3228 - val_accuracy: 0.5800\n",
            "Epoch 47/50\n",
            "92/92 [==============================] - 25s 276ms/step - loss: 1.3243 - accuracy: 0.5747 - val_loss: 1.3148 - val_accuracy: 0.5869\n",
            "Epoch 48/50\n",
            "92/92 [==============================] - 25s 275ms/step - loss: 1.3156 - accuracy: 0.5805 - val_loss: 1.3121 - val_accuracy: 0.5896\n",
            "Epoch 49/50\n",
            "92/92 [==============================] - 25s 276ms/step - loss: 1.3214 - accuracy: 0.5791 - val_loss: 1.3233 - val_accuracy: 0.5841\n",
            "Epoch 50/50\n",
            "92/92 [==============================] - 25s 276ms/step - loss: 1.3522 - accuracy: 0.5437 - val_loss: 1.3470 - val_accuracy: 0.5568\n",
            "INFO:tensorflow:Assets written to: ./tunerbestmodels_e100_5/assets\n",
            "Epoch 1/50\n",
            "92/92 [==============================] - 25s 276ms/step - loss: 1.3049 - accuracy: 0.5961 - val_loss: 1.2950 - val_accuracy: 0.6047\n",
            "Epoch 2/50\n",
            "92/92 [==============================] - 25s 275ms/step - loss: 1.2943 - accuracy: 0.6091 - val_loss: 1.2892 - val_accuracy: 0.6142\n",
            "Epoch 3/50\n",
            "92/92 [==============================] - 25s 276ms/step - loss: 1.2947 - accuracy: 0.6050 - val_loss: 1.2914 - val_accuracy: 0.6033\n",
            "Epoch 4/50\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.2951 - accuracy: 0.6063 - val_loss: 1.2828 - val_accuracy: 0.6197\n",
            "Epoch 5/50\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.2995 - accuracy: 0.6002 - val_loss: 1.2907 - val_accuracy: 0.6088\n",
            "Epoch 6/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 1.2972 - accuracy: 0.6073WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "92/92 [==============================] - 26s 280ms/step - loss: 1.2972 - accuracy: 0.6073 - val_loss: 1.2896 - val_accuracy: 0.6142\n",
            "Epoch 7/50\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.2909 - accuracy: 0.6118 - val_loss: 1.3074 - val_accuracy: 0.5951\n",
            "Epoch 8/50\n",
            "92/92 [==============================] - 25s 273ms/step - loss: 1.3022 - accuracy: 0.5965 - val_loss: 1.2889 - val_accuracy: 0.6129\n",
            "Epoch 9/50\n",
            "92/92 [==============================] - 25s 271ms/step - loss: 1.2996 - accuracy: 0.5995 - val_loss: 1.2937 - val_accuracy: 0.6074\n",
            "Epoch 10/50\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.2969 - accuracy: 0.6026 - val_loss: 1.2787 - val_accuracy: 0.6238\n",
            "Epoch 11/50\n",
            "92/92 [==============================] - 25s 277ms/step - loss: 1.3022 - accuracy: 0.5985 - val_loss: 1.2968 - val_accuracy: 0.6033\n",
            "Epoch 12/50\n",
            "92/92 [==============================] - 25s 275ms/step - loss: 1.3017 - accuracy: 0.5995 - val_loss: 1.2985 - val_accuracy: 0.6019\n",
            "Epoch 13/50\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.2939 - accuracy: 0.6067 - val_loss: 1.2985 - val_accuracy: 0.6019\n",
            "Epoch 14/50\n",
            "92/92 [==============================] - 25s 275ms/step - loss: 1.3041 - accuracy: 0.5982 - val_loss: 1.3058 - val_accuracy: 0.5937\n",
            "Epoch 15/50\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.2834 - accuracy: 0.6186 - val_loss: 1.2926 - val_accuracy: 0.6101\n",
            "Epoch 16/50\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.2957 - accuracy: 0.6033 - val_loss: 1.2774 - val_accuracy: 0.6265\n",
            "Epoch 17/50\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.2854 - accuracy: 0.6176 - val_loss: 1.3117 - val_accuracy: 0.5841\n",
            "Epoch 18/50\n",
            "92/92 [==============================] - 25s 276ms/step - loss: 1.2947 - accuracy: 0.6063 - val_loss: 1.3227 - val_accuracy: 0.5773\n",
            "Epoch 19/50\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.2963 - accuracy: 0.6050 - val_loss: 1.3098 - val_accuracy: 0.5978\n",
            "Epoch 20/50\n",
            "92/92 [==============================] - 25s 276ms/step - loss: 1.2872 - accuracy: 0.6128 - val_loss: 1.3148 - val_accuracy: 0.5855\n",
            "Epoch 21/50\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.3045 - accuracy: 0.5971 - val_loss: 1.3140 - val_accuracy: 0.5882\n",
            "Epoch 22/50\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.3005 - accuracy: 0.6019 - val_loss: 1.2920 - val_accuracy: 0.6088\n",
            "Epoch 23/50\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.2952 - accuracy: 0.6084 - val_loss: 1.2958 - val_accuracy: 0.6047\n",
            "Epoch 24/50\n",
            "92/92 [==============================] - 25s 273ms/step - loss: 1.2935 - accuracy: 0.6073 - val_loss: 1.2969 - val_accuracy: 0.6115\n",
            "Epoch 25/50\n",
            "92/92 [==============================] - 25s 276ms/step - loss: 1.2920 - accuracy: 0.6070 - val_loss: 1.3011 - val_accuracy: 0.5978\n",
            "Epoch 26/50\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.2816 - accuracy: 0.6210 - val_loss: 1.3096 - val_accuracy: 0.5951\n",
            "Epoch 27/50\n",
            "92/92 [==============================] - 25s 272ms/step - loss: 1.2857 - accuracy: 0.6138 - val_loss: 1.2814 - val_accuracy: 0.6211\n",
            "Epoch 28/50\n",
            "92/92 [==============================] - 25s 269ms/step - loss: 1.2969 - accuracy: 0.6033 - val_loss: 1.2955 - val_accuracy: 0.6033\n",
            "Epoch 29/50\n",
            "92/92 [==============================] - 25s 272ms/step - loss: 1.2818 - accuracy: 0.6196 - val_loss: 1.3275 - val_accuracy: 0.5677\n",
            "Epoch 30/50\n",
            "92/92 [==============================] - 25s 276ms/step - loss: 1.2976 - accuracy: 0.6026 - val_loss: 1.3105 - val_accuracy: 0.5923\n",
            "Epoch 31/50\n",
            "92/92 [==============================] - 25s 275ms/step - loss: 1.2877 - accuracy: 0.6121 - val_loss: 1.2915 - val_accuracy: 0.6156\n",
            "Epoch 32/50\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.2934 - accuracy: 0.6080 - val_loss: 1.2842 - val_accuracy: 0.6197\n",
            "Epoch 33/50\n",
            "92/92 [==============================] - 25s 272ms/step - loss: 1.2837 - accuracy: 0.6152 - val_loss: 1.2839 - val_accuracy: 0.6197\n",
            "Epoch 34/50\n",
            "92/92 [==============================] - 25s 273ms/step - loss: 1.2715 - accuracy: 0.6318 - val_loss: 1.2912 - val_accuracy: 0.6101\n",
            "Epoch 35/50\n",
            "92/92 [==============================] - 25s 275ms/step - loss: 1.2929 - accuracy: 0.6067 - val_loss: 1.2974 - val_accuracy: 0.6033\n",
            "Epoch 36/50\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.2797 - accuracy: 0.6182 - val_loss: 1.2727 - val_accuracy: 0.6334\n",
            "Epoch 37/50\n",
            "92/92 [==============================] - 25s 275ms/step - loss: 1.2865 - accuracy: 0.6138 - val_loss: 1.2631 - val_accuracy: 0.6389\n",
            "Epoch 38/50\n",
            "92/92 [==============================] - 25s 273ms/step - loss: 1.2809 - accuracy: 0.6206 - val_loss: 1.2768 - val_accuracy: 0.6211\n",
            "Epoch 39/50\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.2914 - accuracy: 0.6101 - val_loss: 1.2752 - val_accuracy: 0.6293\n",
            "Epoch 40/50\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.2793 - accuracy: 0.6210 - val_loss: 1.2904 - val_accuracy: 0.6101\n",
            "Epoch 41/50\n",
            "92/92 [==============================] - 25s 275ms/step - loss: 1.2811 - accuracy: 0.6193 - val_loss: 1.2872 - val_accuracy: 0.6101\n",
            "Epoch 42/50\n",
            "92/92 [==============================] - 25s 276ms/step - loss: 1.2762 - accuracy: 0.6210 - val_loss: 1.2689 - val_accuracy: 0.6389\n",
            "Epoch 43/50\n",
            "92/92 [==============================] - 25s 275ms/step - loss: 1.3033 - accuracy: 0.5971 - val_loss: 1.2891 - val_accuracy: 0.6115\n",
            "Epoch 44/50\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.3009 - accuracy: 0.5961 - val_loss: 1.2635 - val_accuracy: 0.6402\n",
            "Epoch 45/50\n",
            "92/92 [==============================] - 25s 277ms/step - loss: 1.3101 - accuracy: 0.5886 - val_loss: 1.2744 - val_accuracy: 0.6238\n",
            "Epoch 46/50\n",
            "92/92 [==============================] - 25s 276ms/step - loss: 1.2926 - accuracy: 0.6077 - val_loss: 1.2790 - val_accuracy: 0.6252\n",
            "Epoch 47/50\n",
            "92/92 [==============================] - 25s 276ms/step - loss: 1.2836 - accuracy: 0.6152 - val_loss: 1.2693 - val_accuracy: 0.6306\n",
            "Epoch 48/50\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.2786 - accuracy: 0.6227 - val_loss: 1.2823 - val_accuracy: 0.6211\n",
            "Epoch 49/50\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.2872 - accuracy: 0.6114 - val_loss: 1.2768 - val_accuracy: 0.6252\n",
            "Epoch 50/50\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.2742 - accuracy: 0.6288 - val_loss: 1.2726 - val_accuracy: 0.6265\n",
            "INFO:tensorflow:Assets written to: ./tunerbestmodels_e100_6/assets\n",
            "Epoch 1/50\n",
            "92/92 [==============================] - 25s 273ms/step - loss: 1.3566 - accuracy: 0.5495 - val_loss: 1.3341 - val_accuracy: 0.5622\n",
            "Epoch 2/50\n",
            "92/92 [==============================] - 25s 272ms/step - loss: 1.3497 - accuracy: 0.5587 - val_loss: 1.3421 - val_accuracy: 0.5581\n",
            "Epoch 3/50\n",
            "92/92 [==============================] - 25s 271ms/step - loss: 1.3648 - accuracy: 0.5373 - val_loss: 1.3519 - val_accuracy: 0.5472\n",
            "Epoch 4/50\n",
            "92/92 [==============================] - 25s 270ms/step - loss: 1.3728 - accuracy: 0.5288 - val_loss: 1.3310 - val_accuracy: 0.5650\n",
            "Epoch 5/50\n",
            "92/92 [==============================] - 25s 270ms/step - loss: 1.3434 - accuracy: 0.5597 - val_loss: 1.3462 - val_accuracy: 0.5595\n",
            "Epoch 6/50\n",
            "92/92 [==============================] - 25s 270ms/step - loss: 1.3524 - accuracy: 0.5492 - val_loss: 1.3367 - val_accuracy: 0.5718\n",
            "Epoch 7/50\n",
            "92/92 [==============================] - 25s 271ms/step - loss: 1.3569 - accuracy: 0.5488 - val_loss: 1.3400 - val_accuracy: 0.5636\n",
            "Epoch 8/50\n",
            "92/92 [==============================] - 25s 270ms/step - loss: 1.3437 - accuracy: 0.5607 - val_loss: 1.3249 - val_accuracy: 0.5814\n",
            "Epoch 9/50\n",
            "92/92 [==============================] - 25s 271ms/step - loss: 1.3479 - accuracy: 0.5560 - val_loss: 1.3404 - val_accuracy: 0.5568\n",
            "Epoch 10/50\n",
            "92/92 [==============================] - 25s 271ms/step - loss: 1.3445 - accuracy: 0.5628 - val_loss: 1.3299 - val_accuracy: 0.5677\n",
            "Epoch 11/50\n",
            "92/92 [==============================] - 25s 270ms/step - loss: 1.3428 - accuracy: 0.5652 - val_loss: 1.3432 - val_accuracy: 0.5554\n",
            "Epoch 12/50\n",
            "92/92 [==============================] - 25s 272ms/step - loss: 1.3524 - accuracy: 0.5529 - val_loss: 1.3457 - val_accuracy: 0.5540\n",
            "Epoch 13/50\n",
            "92/92 [==============================] - 25s 269ms/step - loss: 1.3499 - accuracy: 0.5539 - val_loss: 1.3240 - val_accuracy: 0.5800\n",
            "Epoch 14/50\n",
            "92/92 [==============================] - 25s 270ms/step - loss: 1.3402 - accuracy: 0.5621 - val_loss: 1.3418 - val_accuracy: 0.5581\n",
            "Epoch 15/50\n",
            "92/92 [==============================] - 25s 271ms/step - loss: 1.3492 - accuracy: 0.5529 - val_loss: 1.3289 - val_accuracy: 0.5732\n",
            "Epoch 16/50\n",
            "92/92 [==============================] - 25s 270ms/step - loss: 1.3483 - accuracy: 0.5553 - val_loss: 1.3224 - val_accuracy: 0.5787\n",
            "Epoch 17/50\n",
            "92/92 [==============================] - 25s 270ms/step - loss: 1.3396 - accuracy: 0.5638 - val_loss: 1.3450 - val_accuracy: 0.5568\n",
            "Epoch 18/50\n",
            "92/92 [==============================] - 25s 270ms/step - loss: 1.3403 - accuracy: 0.5628 - val_loss: 1.3322 - val_accuracy: 0.5691\n",
            "Epoch 19/50\n",
            "92/92 [==============================] - 25s 270ms/step - loss: 1.3413 - accuracy: 0.5621 - val_loss: 1.3412 - val_accuracy: 0.5595\n",
            "Epoch 20/50\n",
            "92/92 [==============================] - 25s 272ms/step - loss: 1.3378 - accuracy: 0.5696 - val_loss: 1.3294 - val_accuracy: 0.5746\n",
            "Epoch 21/50\n",
            "92/92 [==============================] - 25s 271ms/step - loss: 1.3374 - accuracy: 0.5669 - val_loss: 1.3150 - val_accuracy: 0.5937\n",
            "Epoch 22/50\n",
            "92/92 [==============================] - 25s 270ms/step - loss: 1.3517 - accuracy: 0.5509 - val_loss: 1.3157 - val_accuracy: 0.5882\n",
            "Epoch 23/50\n",
            "92/92 [==============================] - 25s 269ms/step - loss: 1.3407 - accuracy: 0.5635 - val_loss: 1.3274 - val_accuracy: 0.5746\n",
            "Epoch 24/50\n",
            "92/92 [==============================] - 25s 269ms/step - loss: 1.3439 - accuracy: 0.5621 - val_loss: 1.3440 - val_accuracy: 0.5568\n",
            "Epoch 25/50\n",
            "92/92 [==============================] - 25s 271ms/step - loss: 1.3427 - accuracy: 0.5621 - val_loss: 1.3231 - val_accuracy: 0.5718\n",
            "Epoch 26/50\n",
            "92/92 [==============================] - 25s 271ms/step - loss: 1.3472 - accuracy: 0.5532 - val_loss: 1.3283 - val_accuracy: 0.5732\n",
            "Epoch 27/50\n",
            "92/92 [==============================] - 25s 270ms/step - loss: 1.3421 - accuracy: 0.5604 - val_loss: 1.3296 - val_accuracy: 0.5732\n",
            "Epoch 28/50\n",
            "92/92 [==============================] - 25s 269ms/step - loss: 1.3696 - accuracy: 0.5322 - val_loss: 1.5832 - val_accuracy: 0.3215\n",
            "Epoch 29/50\n",
            "92/92 [==============================] - 25s 272ms/step - loss: 1.4775 - accuracy: 0.4246 - val_loss: 1.3320 - val_accuracy: 0.5746\n",
            "Epoch 30/50\n",
            "92/92 [==============================] - 25s 268ms/step - loss: 1.3441 - accuracy: 0.5590 - val_loss: 1.3391 - val_accuracy: 0.5609\n",
            "Epoch 31/50\n",
            "92/92 [==============================] - 25s 270ms/step - loss: 1.3414 - accuracy: 0.5597 - val_loss: 1.3205 - val_accuracy: 0.5814\n",
            "Epoch 32/50\n",
            "92/92 [==============================] - 25s 271ms/step - loss: 1.3413 - accuracy: 0.5631 - val_loss: 1.3225 - val_accuracy: 0.5828\n",
            "Epoch 33/50\n",
            "92/92 [==============================] - 25s 272ms/step - loss: 1.3469 - accuracy: 0.5539 - val_loss: 1.3095 - val_accuracy: 0.5964\n",
            "Epoch 34/50\n",
            "92/92 [==============================] - 25s 271ms/step - loss: 1.3372 - accuracy: 0.5679 - val_loss: 1.3123 - val_accuracy: 0.5882\n",
            "Epoch 35/50\n",
            "92/92 [==============================] - 25s 272ms/step - loss: 1.3342 - accuracy: 0.5709 - val_loss: 1.3287 - val_accuracy: 0.5732\n",
            "Epoch 36/50\n",
            "92/92 [==============================] - 25s 271ms/step - loss: 1.3430 - accuracy: 0.5618 - val_loss: 1.3520 - val_accuracy: 0.5513\n",
            "Epoch 37/50\n",
            "92/92 [==============================] - 25s 270ms/step - loss: 1.3344 - accuracy: 0.5682 - val_loss: 1.3290 - val_accuracy: 0.5746\n",
            "Epoch 38/50\n",
            "92/92 [==============================] - 25s 271ms/step - loss: 1.3372 - accuracy: 0.5648 - val_loss: 1.3594 - val_accuracy: 0.5417\n",
            "Epoch 39/50\n",
            "92/92 [==============================] - 25s 271ms/step - loss: 1.3390 - accuracy: 0.5662 - val_loss: 1.3210 - val_accuracy: 0.5814\n",
            "Epoch 40/50\n",
            "92/92 [==============================] - 25s 270ms/step - loss: 1.3230 - accuracy: 0.5812 - val_loss: 1.3221 - val_accuracy: 0.5787\n",
            "Epoch 41/50\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.3462 - accuracy: 0.5594 - val_loss: 1.3101 - val_accuracy: 0.5910\n",
            "Epoch 42/50\n",
            "92/92 [==============================] - 25s 273ms/step - loss: 1.3297 - accuracy: 0.5733 - val_loss: 1.3047 - val_accuracy: 0.5978\n",
            "Epoch 43/50\n",
            "92/92 [==============================] - 25s 272ms/step - loss: 1.3444 - accuracy: 0.5590 - val_loss: 1.3193 - val_accuracy: 0.5828\n",
            "Epoch 44/50\n",
            "92/92 [==============================] - 25s 273ms/step - loss: 1.3807 - accuracy: 0.5264 - val_loss: 1.3587 - val_accuracy: 0.5417\n",
            "Epoch 45/50\n",
            "92/92 [==============================] - 25s 272ms/step - loss: 1.3402 - accuracy: 0.5628 - val_loss: 1.3270 - val_accuracy: 0.5718\n",
            "Epoch 46/50\n",
            "92/92 [==============================] - 25s 272ms/step - loss: 1.3258 - accuracy: 0.5784 - val_loss: 1.3243 - val_accuracy: 0.5787\n",
            "Epoch 47/50\n",
            "92/92 [==============================] - 25s 270ms/step - loss: 1.3422 - accuracy: 0.5604 - val_loss: 1.3327 - val_accuracy: 0.5732\n",
            "Epoch 48/50\n",
            "92/92 [==============================] - 25s 271ms/step - loss: 1.3291 - accuracy: 0.5740 - val_loss: 1.3268 - val_accuracy: 0.5732\n",
            "Epoch 49/50\n",
            "92/92 [==============================] - 25s 271ms/step - loss: 1.3387 - accuracy: 0.5645 - val_loss: 1.3610 - val_accuracy: 0.5417\n",
            "Epoch 50/50\n",
            "92/92 [==============================] - 25s 272ms/step - loss: 1.3494 - accuracy: 0.5546 - val_loss: 1.3217 - val_accuracy: 0.5814\n",
            "INFO:tensorflow:Assets written to: ./tunerbestmodels_e100_7/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuKMrKGinPyZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Data Plotting for the second round\n",
        "Goal: Find which model is best based on validation metrics.\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "df2 = pd.DataFrame()\n",
        "\n",
        "for i in range(0,3):\n",
        "  df2[['accuracy'+str(i)]] = pd.DataFrame(data2[i].history)[['accuracy']]\n",
        "  df2[['loss'+str(i)]] = pd.DataFrame(data2[i].history)[['loss']]\n",
        "  df2[['val_accuracy'+str(i)]] = pd.DataFrame(data2[i].history)[['val_accuracy']]\n",
        "  df2[['val_loss'+str(i)]] = pd.DataFrame(data2[i].history)[['val_loss']]\n",
        "\n",
        "\n",
        "df2.to_csv(\"Data2.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDpuycS7oEtw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ad8e76fd-f003-41fb-fc00-29e450ca52bb"
      },
      "source": [
        "'''\n",
        "Training what I deem is the \"best model\" based on \n",
        "validation loss and validation accuracy\n",
        "'''\n",
        "\n",
        "m=tf.keras.models.load_model('./tunerbestmodels_e100_2')\n",
        "\n",
        "history = m.fit(\n",
        "    train,\n",
        "    validation_data = val,\n",
        "    epochs=100)\n",
        "tf.keras.models.save_model(m,'./tunerbestmodels_e250_1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "92/92 [==============================] - 25s 276ms/step - loss: 1.2890 - accuracy: 0.6131 - val_loss: 1.2958 - val_accuracy: 0.6060\n",
            "Epoch 2/100\n",
            "92/92 [==============================] - 25s 275ms/step - loss: 1.2831 - accuracy: 0.6182 - val_loss: 1.2726 - val_accuracy: 0.6279\n",
            "Epoch 3/100\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.2763 - accuracy: 0.6237 - val_loss: 1.2852 - val_accuracy: 0.6197\n",
            "Epoch 4/100\n",
            "92/92 [==============================] - 25s 275ms/step - loss: 1.2862 - accuracy: 0.6145 - val_loss: 1.2672 - val_accuracy: 0.6347\n",
            "Epoch 5/100\n",
            "92/92 [==============================] - 25s 275ms/step - loss: 1.3087 - accuracy: 0.5914 - val_loss: 1.2861 - val_accuracy: 0.6252\n",
            "Epoch 6/100\n",
            "92/92 [==============================] - 25s 273ms/step - loss: 1.2966 - accuracy: 0.6053 - val_loss: 1.3098 - val_accuracy: 0.5937\n",
            "Epoch 7/100\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.2972 - accuracy: 0.6036 - val_loss: 1.2899 - val_accuracy: 0.6156\n",
            "Epoch 8/100\n",
            "92/92 [==============================] - 25s 275ms/step - loss: 1.2777 - accuracy: 0.6261 - val_loss: 1.2732 - val_accuracy: 0.6293\n",
            "Epoch 9/100\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.2881 - accuracy: 0.6131 - val_loss: 1.2871 - val_accuracy: 0.6074\n",
            "Epoch 10/100\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.2757 - accuracy: 0.6247 - val_loss: 1.2701 - val_accuracy: 0.6320\n",
            "Epoch 11/100\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.2748 - accuracy: 0.6250 - val_loss: 1.2779 - val_accuracy: 0.6252\n",
            "Epoch 12/100\n",
            "92/92 [==============================] - 25s 275ms/step - loss: 1.2663 - accuracy: 0.6349 - val_loss: 1.2792 - val_accuracy: 0.6183\n",
            "Epoch 13/100\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.2786 - accuracy: 0.6257 - val_loss: 1.2679 - val_accuracy: 0.6334\n",
            "Epoch 14/100\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.2768 - accuracy: 0.6237 - val_loss: 1.2884 - val_accuracy: 0.6156\n",
            "Epoch 15/100\n",
            "92/92 [==============================] - 25s 273ms/step - loss: 1.2862 - accuracy: 0.6131 - val_loss: 1.2829 - val_accuracy: 0.6197\n",
            "Epoch 16/100\n",
            "92/92 [==============================] - 25s 275ms/step - loss: 1.2912 - accuracy: 0.6080 - val_loss: 1.2851 - val_accuracy: 0.6129\n",
            "Epoch 17/100\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.2797 - accuracy: 0.6233 - val_loss: 1.2680 - val_accuracy: 0.6320\n",
            "Epoch 18/100\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.2726 - accuracy: 0.6322 - val_loss: 1.2856 - val_accuracy: 0.6142\n",
            "Epoch 19/100\n",
            "92/92 [==============================] - 25s 273ms/step - loss: 1.2865 - accuracy: 0.6152 - val_loss: 1.3250 - val_accuracy: 0.5773\n",
            "Epoch 20/100\n",
            "92/92 [==============================] - 25s 275ms/step - loss: 1.2815 - accuracy: 0.6203 - val_loss: 1.2716 - val_accuracy: 0.6265\n",
            "Epoch 21/100\n",
            "92/92 [==============================] - 25s 273ms/step - loss: 1.2980 - accuracy: 0.6063 - val_loss: 1.2946 - val_accuracy: 0.6033\n",
            "Epoch 22/100\n",
            "92/92 [==============================] - 25s 272ms/step - loss: 1.2900 - accuracy: 0.6111 - val_loss: 1.2852 - val_accuracy: 0.6170\n",
            "Epoch 23/100\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.2853 - accuracy: 0.6155 - val_loss: 1.3001 - val_accuracy: 0.5951\n",
            "Epoch 24/100\n",
            "92/92 [==============================] - 25s 274ms/step - loss: 1.2802 - accuracy: 0.6193 - val_loss: 1.2716 - val_accuracy: 0.6347\n",
            "Epoch 25/100\n",
            "92/92 [==============================] - 25s 273ms/step - loss: 1.3052 - accuracy: 0.5948 - val_loss: 1.3104 - val_accuracy: 0.5855\n",
            "Epoch 26/100\n",
            "92/92 [==============================] - 25s 271ms/step - loss: 1.2823 - accuracy: 0.6169 - val_loss: 1.2779 - val_accuracy: 0.6224\n",
            "Epoch 27/100\n",
            "92/92 [==============================] - 25s 269ms/step - loss: 1.2723 - accuracy: 0.6308 - val_loss: 1.2713 - val_accuracy: 0.6293\n",
            "Epoch 28/100\n",
            "92/92 [==============================] - 25s 272ms/step - loss: 1.2753 - accuracy: 0.6233 - val_loss: 1.2906 - val_accuracy: 0.6101\n",
            "Epoch 29/100\n",
            "92/92 [==============================] - 25s 273ms/step - loss: 1.2765 - accuracy: 0.6220 - val_loss: 1.2709 - val_accuracy: 0.6293\n",
            "Epoch 30/100\n",
            "92/92 [==============================] - 25s 271ms/step - loss: 1.2819 - accuracy: 0.6169 - val_loss: 1.2911 - val_accuracy: 0.6142\n",
            "Epoch 31/100\n",
            "92/92 [==============================] - 25s 275ms/step - loss: 1.2732 - accuracy: 0.6254 - val_loss: 1.2784 - val_accuracy: 0.6265\n",
            "Epoch 32/100\n",
            "92/92 [==============================] - 25s 275ms/step - loss: 1.2693 - accuracy: 0.6315 - val_loss: 1.2661 - val_accuracy: 0.6402\n",
            "Epoch 33/100\n",
            "92/92 [==============================] - 26s 283ms/step - loss: 1.2709 - accuracy: 0.6301 - val_loss: 1.2990 - val_accuracy: 0.6019\n",
            "Epoch 34/100\n",
            "92/92 [==============================] - 25s 275ms/step - loss: 1.3154 - accuracy: 0.5835 - val_loss: 1.2958 - val_accuracy: 0.5964\n",
            "Epoch 35/100\n",
            "92/92 [==============================] - 26s 282ms/step - loss: 1.2830 - accuracy: 0.6186 - val_loss: 1.2551 - val_accuracy: 0.6539\n",
            "Epoch 36/100\n",
            "92/92 [==============================] - 27s 298ms/step - loss: 1.2649 - accuracy: 0.6383 - val_loss: 1.2707 - val_accuracy: 0.6306\n",
            "Epoch 37/100\n",
            "92/92 [==============================] - 27s 296ms/step - loss: 1.2753 - accuracy: 0.6254 - val_loss: 1.2595 - val_accuracy: 0.6430\n",
            "Epoch 38/100\n",
            "92/92 [==============================] - 27s 296ms/step - loss: 1.2727 - accuracy: 0.6288 - val_loss: 1.2735 - val_accuracy: 0.6279\n",
            "Epoch 39/100\n",
            "92/92 [==============================] - 27s 299ms/step - loss: 1.2824 - accuracy: 0.6193 - val_loss: 1.3175 - val_accuracy: 0.5800\n",
            "Epoch 40/100\n",
            "92/92 [==============================] - 27s 297ms/step - loss: 1.2814 - accuracy: 0.6162 - val_loss: 1.2844 - val_accuracy: 0.6197\n",
            "Epoch 41/100\n",
            "92/92 [==============================] - 27s 299ms/step - loss: 1.2750 - accuracy: 0.6240 - val_loss: 1.2906 - val_accuracy: 0.6060\n",
            "Epoch 42/100\n",
            "92/92 [==============================] - 27s 297ms/step - loss: 1.2786 - accuracy: 0.6233 - val_loss: 1.2766 - val_accuracy: 0.6211\n",
            "Epoch 43/100\n",
            "92/92 [==============================] - 28s 300ms/step - loss: 1.2673 - accuracy: 0.6359 - val_loss: 1.2591 - val_accuracy: 0.6389\n",
            "Epoch 44/100\n",
            "92/92 [==============================] - 28s 303ms/step - loss: 1.2684 - accuracy: 0.6315 - val_loss: 1.2736 - val_accuracy: 0.6306\n",
            "Epoch 45/100\n",
            "92/92 [==============================] - 28s 300ms/step - loss: 1.2784 - accuracy: 0.6230 - val_loss: 1.2818 - val_accuracy: 0.6238\n",
            "Epoch 46/100\n",
            "92/92 [==============================] - 27s 298ms/step - loss: 1.2602 - accuracy: 0.6414 - val_loss: 1.2805 - val_accuracy: 0.6197\n",
            "Epoch 47/100\n",
            "92/92 [==============================] - 28s 299ms/step - loss: 1.2712 - accuracy: 0.6284 - val_loss: 1.2701 - val_accuracy: 0.6306\n",
            "Epoch 48/100\n",
            "92/92 [==============================] - 27s 296ms/step - loss: 1.2756 - accuracy: 0.6271 - val_loss: 1.2594 - val_accuracy: 0.6402\n",
            "Epoch 49/100\n",
            "92/92 [==============================] - 27s 294ms/step - loss: 1.2682 - accuracy: 0.6329 - val_loss: 1.2672 - val_accuracy: 0.6334\n",
            "Epoch 50/100\n",
            "92/92 [==============================] - 27s 291ms/step - loss: 1.2679 - accuracy: 0.6332 - val_loss: 1.2552 - val_accuracy: 0.6498\n",
            "Epoch 51/100\n",
            "92/92 [==============================] - 27s 293ms/step - loss: 1.2723 - accuracy: 0.6291 - val_loss: 1.3008 - val_accuracy: 0.6019\n",
            "Epoch 52/100\n",
            "92/92 [==============================] - 28s 299ms/step - loss: 1.2728 - accuracy: 0.6288 - val_loss: 1.2673 - val_accuracy: 0.6361\n",
            "Epoch 53/100\n",
            "92/92 [==============================] - 28s 304ms/step - loss: 1.2637 - accuracy: 0.6363 - val_loss: 1.2739 - val_accuracy: 0.6265\n",
            "Epoch 54/100\n",
            "92/92 [==============================] - 27s 298ms/step - loss: 1.2615 - accuracy: 0.6387 - val_loss: 1.2733 - val_accuracy: 0.6265\n",
            "Epoch 55/100\n",
            "92/92 [==============================] - 27s 299ms/step - loss: 1.2676 - accuracy: 0.6332 - val_loss: 1.2896 - val_accuracy: 0.6142\n",
            "Epoch 56/100\n",
            "92/92 [==============================] - 28s 300ms/step - loss: 1.2709 - accuracy: 0.6315 - val_loss: 1.2699 - val_accuracy: 0.6293\n",
            "Epoch 57/100\n",
            "92/92 [==============================] - 28s 301ms/step - loss: 1.2826 - accuracy: 0.6162 - val_loss: 1.2668 - val_accuracy: 0.6361\n",
            "Epoch 58/100\n",
            "92/92 [==============================] - 28s 302ms/step - loss: 1.2838 - accuracy: 0.6176 - val_loss: 1.2804 - val_accuracy: 0.6197\n",
            "Epoch 59/100\n",
            "92/92 [==============================] - 27s 296ms/step - loss: 1.2790 - accuracy: 0.6213 - val_loss: 1.2702 - val_accuracy: 0.6306\n",
            "Epoch 60/100\n",
            "92/92 [==============================] - 27s 292ms/step - loss: 1.2735 - accuracy: 0.6295 - val_loss: 1.2725 - val_accuracy: 0.6306\n",
            "Epoch 61/100\n",
            "92/92 [==============================] - 27s 298ms/step - loss: 1.2787 - accuracy: 0.6213 - val_loss: 1.2926 - val_accuracy: 0.6060\n",
            "Epoch 62/100\n",
            "92/92 [==============================] - 27s 299ms/step - loss: 1.2948 - accuracy: 0.6039 - val_loss: 1.2767 - val_accuracy: 0.6252\n",
            "Epoch 63/100\n",
            "92/92 [==============================] - 27s 298ms/step - loss: 1.2685 - accuracy: 0.6318 - val_loss: 1.2639 - val_accuracy: 0.6361\n",
            "Epoch 64/100\n",
            "92/92 [==============================] - 27s 298ms/step - loss: 1.2780 - accuracy: 0.6240 - val_loss: 1.2794 - val_accuracy: 0.6197\n",
            "Epoch 65/100\n",
            "92/92 [==============================] - 27s 298ms/step - loss: 1.2793 - accuracy: 0.6216 - val_loss: 1.2677 - val_accuracy: 0.6347\n",
            "Epoch 66/100\n",
            "92/92 [==============================] - 27s 297ms/step - loss: 1.2925 - accuracy: 0.6097 - val_loss: 1.3041 - val_accuracy: 0.5951\n",
            "Epoch 67/100\n",
            "92/92 [==============================] - 28s 301ms/step - loss: 1.2783 - accuracy: 0.6210 - val_loss: 1.2700 - val_accuracy: 0.6293\n",
            "Epoch 68/100\n",
            "92/92 [==============================] - 27s 298ms/step - loss: 1.2714 - accuracy: 0.6298 - val_loss: 1.2708 - val_accuracy: 0.6279\n",
            "Epoch 69/100\n",
            "92/92 [==============================] - 28s 299ms/step - loss: 1.2734 - accuracy: 0.6254 - val_loss: 1.2633 - val_accuracy: 0.6375\n",
            "Epoch 70/100\n",
            "92/92 [==============================] - 27s 299ms/step - loss: 1.2747 - accuracy: 0.6247 - val_loss: 1.3011 - val_accuracy: 0.6019\n",
            "Epoch 71/100\n",
            "92/92 [==============================] - 27s 298ms/step - loss: 1.2931 - accuracy: 0.6091 - val_loss: 1.2942 - val_accuracy: 0.6101\n",
            "Epoch 72/100\n",
            "92/92 [==============================] - 28s 299ms/step - loss: 1.2716 - accuracy: 0.6264 - val_loss: 1.2555 - val_accuracy: 0.6484\n",
            "Epoch 73/100\n",
            "92/92 [==============================] - 28s 301ms/step - loss: 1.2839 - accuracy: 0.6169 - val_loss: 1.2544 - val_accuracy: 0.6471\n",
            "Epoch 74/100\n",
            "92/92 [==============================] - 28s 300ms/step - loss: 1.2792 - accuracy: 0.6206 - val_loss: 1.2643 - val_accuracy: 0.6375\n",
            "Epoch 75/100\n",
            "92/92 [==============================] - 28s 305ms/step - loss: 1.2775 - accuracy: 0.6210 - val_loss: 1.2626 - val_accuracy: 0.6361\n",
            "Epoch 76/100\n",
            "92/92 [==============================] - 28s 302ms/step - loss: 1.2698 - accuracy: 0.6322 - val_loss: 1.2711 - val_accuracy: 0.6279\n",
            "Epoch 77/100\n",
            "92/92 [==============================] - 28s 302ms/step - loss: 1.2845 - accuracy: 0.6176 - val_loss: 1.3006 - val_accuracy: 0.5978\n",
            "Epoch 78/100\n",
            "92/92 [==============================] - 28s 304ms/step - loss: 1.2752 - accuracy: 0.6244 - val_loss: 1.2414 - val_accuracy: 0.6621\n",
            "Epoch 79/100\n",
            "92/92 [==============================] - 28s 301ms/step - loss: 1.2864 - accuracy: 0.6172 - val_loss: 1.3062 - val_accuracy: 0.5978\n",
            "Epoch 80/100\n",
            "92/92 [==============================] - 28s 303ms/step - loss: 1.2826 - accuracy: 0.6193 - val_loss: 1.2849 - val_accuracy: 0.6142\n",
            "Epoch 81/100\n",
            "92/92 [==============================] - 27s 297ms/step - loss: 1.2874 - accuracy: 0.6145 - val_loss: 1.2652 - val_accuracy: 0.6430\n",
            "Epoch 82/100\n",
            "92/92 [==============================] - 28s 301ms/step - loss: 1.3083 - accuracy: 0.5924 - val_loss: 1.2934 - val_accuracy: 0.6047\n",
            "Epoch 83/100\n",
            "92/92 [==============================] - 28s 300ms/step - loss: 1.2809 - accuracy: 0.6199 - val_loss: 1.2520 - val_accuracy: 0.6512\n",
            "Epoch 84/100\n",
            "92/92 [==============================] - 28s 301ms/step - loss: 1.3044 - accuracy: 0.5965 - val_loss: 1.2921 - val_accuracy: 0.6101\n",
            "Epoch 85/100\n",
            "92/92 [==============================] - 28s 300ms/step - loss: 1.2897 - accuracy: 0.6131 - val_loss: 1.2612 - val_accuracy: 0.6416\n",
            "Epoch 86/100\n",
            "92/92 [==============================] - 28s 299ms/step - loss: 1.2874 - accuracy: 0.6169 - val_loss: 1.2510 - val_accuracy: 0.6553\n",
            "Epoch 87/100\n",
            "92/92 [==============================] - 28s 301ms/step - loss: 1.2738 - accuracy: 0.6298 - val_loss: 1.2682 - val_accuracy: 0.6320\n",
            "Epoch 88/100\n",
            "92/92 [==============================] - 27s 294ms/step - loss: 1.2768 - accuracy: 0.6247 - val_loss: 1.2804 - val_accuracy: 0.6211\n",
            "Epoch 89/100\n",
            "92/92 [==============================] - 27s 291ms/step - loss: 1.2708 - accuracy: 0.6325 - val_loss: 1.2689 - val_accuracy: 0.6375\n",
            "Epoch 90/100\n",
            "92/92 [==============================] - 27s 291ms/step - loss: 1.2650 - accuracy: 0.6393 - val_loss: 1.2837 - val_accuracy: 0.6183\n",
            "Epoch 91/100\n",
            "92/92 [==============================] - 27s 293ms/step - loss: 1.2912 - accuracy: 0.6101 - val_loss: 1.2833 - val_accuracy: 0.6156\n",
            "Epoch 92/100\n",
            "92/92 [==============================] - 27s 292ms/step - loss: 1.2721 - accuracy: 0.6312 - val_loss: 1.2802 - val_accuracy: 0.6197\n",
            "Epoch 93/100\n",
            "92/92 [==============================] - 27s 291ms/step - loss: 1.2853 - accuracy: 0.6189 - val_loss: 1.2887 - val_accuracy: 0.6129\n",
            "Epoch 94/100\n",
            "92/92 [==============================] - 27s 288ms/step - loss: 1.2847 - accuracy: 0.6182 - val_loss: 1.2589 - val_accuracy: 0.6443\n",
            "Epoch 95/100\n",
            "92/92 [==============================] - 26s 288ms/step - loss: 1.2620 - accuracy: 0.6373 - val_loss: 1.2714 - val_accuracy: 0.6334\n",
            "Epoch 96/100\n",
            "92/92 [==============================] - 27s 295ms/step - loss: 1.2629 - accuracy: 0.6427 - val_loss: 1.2672 - val_accuracy: 0.6389\n",
            "Epoch 97/100\n",
            "92/92 [==============================] - 27s 293ms/step - loss: 1.2819 - accuracy: 0.6186 - val_loss: 1.2964 - val_accuracy: 0.6088\n",
            "Epoch 98/100\n",
            "92/92 [==============================] - 27s 289ms/step - loss: 1.2916 - accuracy: 0.6097 - val_loss: 1.2620 - val_accuracy: 0.6416\n",
            "Epoch 99/100\n",
            "92/92 [==============================] - 27s 288ms/step - loss: 1.2940 - accuracy: 0.6070 - val_loss: 1.2796 - val_accuracy: 0.6197\n",
            "Epoch 100/100\n",
            "92/92 [==============================] - 27s 291ms/step - loss: 1.2533 - accuracy: 0.6512 - val_loss: 1.2602 - val_accuracy: 0.6430\n",
            "INFO:tensorflow:Assets written to: ./tunerbestmodels_e250_1/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4_OXa8OIth6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7767bfc6-c501-4887-db18-afc457b8169e"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "'''\n",
        "Here, I do a somewhat informal test by downloading pictures\n",
        "and putting them through the model.\n",
        "\n",
        "Some observations:\n",
        "\n",
        "-Daisy identification looks fine?\n",
        "-Dandelions are confused for sunflowers?\n",
        "-The model seems to confuse roses for tulips and vice-versa?\n",
        "-Sunflower identification seems okay?\n",
        "\n",
        "Softmaxing may not be a good idea in hindsight as the loss of probability \n",
        "information making seeing uncertainty impossible.\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Class Indices\n",
        "{'daisy': 0, 'dandelion': 1, 'roses': 2, 'sunflowers': 3, 'tulips': 4}\n",
        "'''\n",
        "\n",
        "flower = image.load_img('/content/tulip2.jpg',target_size=(128,128))\n",
        "flower = image.img_to_array(flower)\n",
        "flower = np.expand_dims(flower,axis=0)\n",
        "m=tf.keras.models.load_model('/content/tunerbestmodels_e250_1')\n",
        "\n",
        "print(m.predict(flower))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 1.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nClass Indices\\n{'daisy': 0, 'dandelion': 1, 'roses': 2, 'sunflowers': 3, 'tulips': 4}\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SySh-5KaUaGt",
        "colab_type": "text"
      },
      "source": [
        "For next time, CNN model design could use more work.\n",
        "\n",
        "The \"post-Hyperband rounds of training\" data are contained in CSV files and the best model is included."
      ]
    }
  ]
}