{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YelpPolarity",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQlK_PhDgUdO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "92c4afb6-df89-48e3-aeb3-676bd61fcedc"
      },
      "source": [
        "'''\n",
        "Dataset Description: https://www.tensorflow.org/datasets/catalog/yelp_polarity_reviews\n",
        "Dataset Homepage: https://course.fast.ai/datasets\n",
        "Dataset Download: https://s3.amazonaws.com/fast-ai-nlp/yelp_review_polarity_csv.tgz\n",
        "\n",
        "In short, Yelp reviews in two categories: Bad and Good\n",
        "'''\n",
        "\n",
        "#Download \n",
        "!wget -nc  https://s3.amazonaws.com/fast-ai-nlp/yelp_review_polarity_csv.tgz\n",
        "!tar xzf '/content/yelp_review_polarity_csv.tgz'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-22 12:07:08--  https://s3.amazonaws.com/fast-ai-nlp/yelp_review_polarity_csv.tgz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.112.229\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.112.229|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 166373201 (159M) [application/x-tar]\n",
            "Saving to: ‘yelp_review_polarity_csv.tgz’\n",
            "\n",
            "yelp_review_polarit 100%[===================>] 158.67M  16.1MB/s    in 11s     \n",
            "\n",
            "2020-07-22 12:07:20 (14.4 MB/s) - ‘yelp_review_polarity_csv.tgz’ saved [166373201/166373201]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uN5nLRq_7qDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Read text data.\n",
        "'''\n",
        "from pandas import read_csv\n",
        "import math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "from functools import reduce\n",
        "from tensorflow.data import Dataset\n",
        "\n",
        "def massage(x):\n",
        "  return (x[1].encode('UTF-8'),x[0])\n",
        "def encode(text,rating):\n",
        "  encodedText = encoder.encode(text.numpy())\n",
        "  return encodedText, rating-1\n",
        "\n",
        "def encodeMapFunc(text,label):\n",
        "  encodedText, label = tf.py_function(encode,\n",
        "                                      inp=[text,label],\n",
        "                                      Tout=(tf.int64,tf.int64))\n",
        "  \n",
        "  encodedText.set_shape([None])\n",
        "  label.set_shape([])\n",
        "  return encodedText,label\n",
        "\n",
        "\n",
        "rawTrain = read_csv('/content/yelp_review_polarity_csv/train.csv').set_axis(['rating','text'],axis='columns')\n",
        "rawTest = read_csv('/content/yelp_review_polarity_csv/test.csv').set_axis(['rating','text'],axis='columns')\n",
        "\n",
        "train = rawTrain.apply(massage,axis=1,result_type='expand').set_axis(['text','rating'],axis='columns')\n",
        "trainTexts = train.pop('text')\n",
        "trainRatings = train.pop('rating')\n",
        "train = Dataset.from_tensor_slices((trainTexts,trainRatings))\n",
        "\n",
        "test = rawTest.apply(massage,axis=1,result_type='expand').set_axis(['text','rating'],axis='columns')\n",
        "testTexts = test.pop('text')\n",
        "testRatings = test.pop('rating')\n",
        "test = Dataset.from_tensor_slices((testTexts,testRatings))\n",
        "\n",
        "tokenizer = tfds.features.text.Tokenizer()\n",
        "vocab = set()\n",
        "for data in [trainTexts,testTexts]:\n",
        "  for text,label in train:\n",
        "    tokens = tokenizer.tokenize(text.numpy())\n",
        "    vocab.update(tokens)\n",
        "encoder = tfds.features.text.TokenTextEncoder(vocab)\n",
        "\n",
        "train = train.map(encodeMapFunc)\n",
        "train = train.shuffle(10000)\n",
        "train = train.padded_batch(128)\n",
        "\n",
        "\n",
        "test = test.map(encodeMapFunc)\n",
        "test = test.shuffle(10000)\n",
        "test = test.padded_batch(128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoJiMr1Muctl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "outputId": "36bf8c97-2ba4-4fbc-b775-6f0aaae4eef7"
      },
      "source": [
        "'''\n",
        "Model structure.\n",
        "'''\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "  Embedding(encoder.vocab_size,64),\n",
        "  Bidirectional(LSTM(64, return_sequences=True)),\n",
        "  Dropout(0.5),\n",
        "  Bidirectional(LSTM(64)),\n",
        "  Dropout(0.5),\n",
        "  Dense(128),\n",
        "  Dropout(0.5),\n",
        "  Dense(1,activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, None, 64)          19080448  \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, None, 128)         66048     \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, None, 128)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional_7 (Bidirection (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 19,261,953\n",
            "Trainable params: 19,261,953\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPFPOQBcz-Ga",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "31fd89e9-2ce5-4798-efd5-d7ca87d67961"
      },
      "source": [
        "'''\n",
        "Train Model\n",
        "'''\n",
        "\n",
        "model.fit(train,epochs=3,validation_data=test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "4375/4375 [==============================] - 3252s 743ms/step - loss: 0.2060 - accuracy: 0.9177 - val_loss: 0.1207 - val_accuracy: 0.9545\n",
            "Epoch 2/3\n",
            "4375/4375 [==============================] - 3238s 740ms/step - loss: 0.1029 - accuracy: 0.9627 - val_loss: 0.1308 - val_accuracy: 0.9569\n",
            "Epoch 3/3\n",
            "4375/4375 [==============================] - 3240s 741ms/step - loss: 0.0722 - accuracy: 0.9750 - val_loss: 0.1330 - val_accuracy: 0.9551\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1a99dac518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdk3cdlQNJwc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "508b21f8-fa03-480e-8079-a7b0201392de"
      },
      "source": [
        "'''\n",
        "Save Model and encoder\n",
        "'''\n",
        "from tensorflow.keras.models import save_model\n",
        "save_model(model,'./polarYelpReviewerModel_Epochs00003')\n",
        "encoder.save_to_file(\"./polarYelpEncoder\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./polarYelpReviewerModel_Epochs00003/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuwlFchkOHJi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "bd39e829-aefd-429c-cd7e-981e95dc2d21"
      },
      "source": [
        "'''\n",
        "Small trial and test.\n",
        "\n",
        "Negation appears to not be understood by the model.\n",
        "'''\n",
        "goodTexts = [\n",
        "  \"I love it.\", \n",
        "  \"You cannot hate it.\",\n",
        "  \"Beautiful place.\"]\n",
        "goodTexts = [encoder.encode(x) for x in goodTexts]\n",
        "for i in range(len(goodTexts)):\n",
        "  print(model.predict(tf.expand_dims(goodTexts[i], 0)))\n",
        "\n",
        "badTexts = [\n",
        "\"I hate it.\", \n",
        "\"You cannot love it.\",\n",
        "\"Ugly place.\"]\n",
        "badTexts = [encoder.encode(x) for x in badTexts]\n",
        "for i in range(len(badTexts)):\n",
        "  print(model.predict(tf.expand_dims(badTexts[i], 0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.99363303]]\n",
            "[[0.2584478]]\n",
            "[[0.9897226]]\n",
            "[[0.00644007]]\n",
            "[[0.9691264]]\n",
            "[[0.09578083]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}