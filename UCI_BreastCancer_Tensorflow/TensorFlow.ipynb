{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports and data imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Using UCI Machine Learning Repository's database.\n",
    "#Using data from the \" Breast Cancer Wisconsin (Diagnostic) Data Set\" (https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29)\n",
    "#Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science. \n",
    "\n",
    "#Reading CSV Data into Pandas\n",
    "col_names = [\n",
    "    \"id\",\n",
    "    \"diagnosis\",\n",
    "    \"radius_mean\",\n",
    "    \"texture_mean\",\n",
    "    \"perimeter_mean\",\n",
    "    \"area_mean\",\n",
    "    \"smoothness_mean\",\n",
    "    \"compactness_mean\",\n",
    "    \"concavity_mean\",\n",
    "    \"concave_points_mean\",\n",
    "    \"symmetry_mean\",\n",
    "    \"fractal_dimension_mean\",\n",
    "    \"radius_standard_error\",\n",
    "    \"texture_standard_error\",\n",
    "    \"perimeter_standard_error\",\n",
    "    \"area_standard_error\",\n",
    "    \"smoothness_standard_error\",\n",
    "    \"compactness_standard_error\",\n",
    "    \"concavity_standard_error\",\n",
    "    \"concave_points_standard_error\",\n",
    "    \"symmetry_standard_error\",\n",
    "    \"fractal_dimension_standard_error\",\n",
    "    \"radius_worst\",\n",
    "    \"texture_worst\",\n",
    "    \"perimeter_worst\",\n",
    "    \"area_worst\",\n",
    "    \"smoothness_worst\",\n",
    "    \"compactness_worst\",\n",
    "    \"concavity_worst\",\n",
    "    \"concave_points_worst\",\n",
    "    \"symmetry_worst\",\n",
    "    \"fractal_dimension_worst\"\n",
    "]\n",
    "raw_data = pd.read_csv(\n",
    "    \"./wdbc.data\",\n",
    "    names=col_names,\n",
    "    na_values=\"?\")\n",
    "\n",
    "\n",
    "def massage_data(df):\n",
    "    \n",
    "    #Drop unknown values\n",
    "    df = df.dropna()\n",
    "    \n",
    "    #One-hot encoding for only the feature\n",
    "    col = \"diagnosis\"\n",
    "    one_hot = pd.get_dummies(df[col])\n",
    "    df = df.drop(col,axis=1)\n",
    "    df = df.join(one_hot)\n",
    "        \n",
    "    #separating into features and labels\n",
    "    #ID is irrelevant data, so skip the first column\n",
    "    features = df[df.columns[1:-2]]\n",
    "    labels = df[df.columns[-2:]]\n",
    "    \n",
    "    #Feature normalization\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    features = min_max_scaler.fit_transform(features)\n",
    "    \n",
    "    #Added to make concat in the future work.\n",
    "    #May or may not be bad practice.\n",
    "    labels = min_max_scaler.fit_transform(labels) \n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "all_features, all_labels = massage_data(raw_training)\n",
    "training_features, testing_features, training_labels, testing_labels = train_test_split(all_features, all_labels, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.3536 - accuracy: 0.9560\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "#Training and saving models.\n",
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Flatten(input_shape=(30,)),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(30, activation='elu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(30, activation='elu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(2, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    \n",
    "    model.compile(loss=loss,\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"./checkpoints/cp-{epoch:04d}.ckpt\", \n",
    "    verbose=0, \n",
    "    save_freq='epoch')\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    training_features,\n",
    "    training_labels,\n",
    "    epochs=20,\n",
    "    callbacks=[checkpoint],\n",
    "    verbose=0)\n",
    "\n",
    "clear_output()\n",
    "\n",
    "#Accuracy in a NN ranges between 0.8 and 1.0.\n",
    "#When the decision tree is subject to the test split, its best accuracy is worse.\n",
    "testing_loss, testing_accuracy = model.evaluate(testing_features,testing_labels,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99062574 0.00937422]\n",
      " [0.99522746 0.0047725 ]\n",
      " [0.94895905 0.05104094]\n",
      " [0.9964205  0.00357949]\n",
      " [0.8991218  0.10087816]\n",
      " [0.89266884 0.10733119]\n",
      " [0.9917957  0.00820429]\n",
      " [0.98639536 0.01360462]]\n"
     ]
    }
   ],
   "source": [
    "#Predictions on speculative examples.\n",
    "#These examples are built from the decision tree.\n",
    "features_df = pd.DataFrame(all_features, columns=col_names[2:])\n",
    "labels_df = pd.DataFrame(all_labels, columns=['B','M'])\n",
    "total_normalized_df = pd.concat([features_df, labels_df], axis=1)\n",
    "\n",
    "#Based on the decision tree in the other file, these should only be Beign.\n",
    "onlyB = total_normalized_df[total_normalized_df.radius_worst > 0.315]\n",
    "onlyB = onlyB[onlyB.texture_mean <= 0.216]\n",
    "onlyB = onlyB[onlyB.compactness_standard_error <= 0.139]\n",
    "\n",
    "#The model should predict that these are Beign.\n",
    "features_onlyB = onlyB[onlyB.columns[:-2]]\n",
    "print(model.predict(features_onlyB))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
